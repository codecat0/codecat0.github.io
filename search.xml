<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>FCN</title>
    <url>/2021/12/30/FCN/</url>
    <content><![CDATA[<h1 id="FCN论文详解"><a href="#FCN论文详解" class="headerlink" title="FCN论文详解"></a>FCN论文详解</h1><blockquote>
<p>FCN全卷积网络是图像分割开山之作，其核心思想非常简单，用卷积层代替分类网络中的全连接层。</p>
</blockquote>
<span id="more"></span>
<h2 id="1-将全连接层替换为卷积层"><a href="#1-将全连接层替换为卷积层" class="headerlink" title="1. 将全连接层替换为卷积层"></a>1. 将全连接层替换为卷积层</h2><p>语义分割的目的是<strong>对图像中每一个像素点进行分类</strong>，与普通的分类任务只输出图像某个类别不同，<strong>语义分割任务输出的是与输入图像大小相同的图像，输出图像的每个像素对应输入图像每个像素的类别</strong>，这也就是论文中提到的<code>dense prediction</code>。</p>
<p>FCN全卷积网络是图像分割开山之作，其核心思想非常简单，<strong>用卷积层代替分类网络中的全连接层。</strong><br><img src="https://img-blog.csdnimg.cn/781c58979f904f4a8f9f2fcc1b8fd57e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5L2V5aaC5Y2D5rO3,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<p>用于分类的神经网络由卷积层、池化层和最后连接的全连接层组成，<strong>经过最后的全连接层后，二维的图像信息被映射为具体的一维类别信息进行输出，得到分类标签。</strong></p>
<p>对于语义分割问题，我们需要的不是具体的类别标签，而是一个二维的分割图，<strong>FCN方法丢弃全连接层，并将其换成卷积层，最后输出与原图相同大小的分割图</strong></p>
<p><strong>论文作者认为：全连接层让目标的位置信息消失了，只保留了语义信息，而将全连接层更换为卷积层可以同时保留位置信息和语义信息</strong><br><img src="https://img-blog.csdnimg.cn/21e775adbf0d437887fe31716099c2f4.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5L2V5aaC5Y2D5rO3,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<h2 id="2-上采样"><a href="#2-上采样" class="headerlink" title="2. 上采样"></a>2. 上采样</h2><p>由于经过<strong>多次卷积之后图像的大小会缩小</strong>，需要通过<strong>上采样</strong>对其进行尺寸大小的恢复，<strong>使最后的分割图与原图尺寸一样</strong></p>
<h3 id="2-1-反卷积"><a href="#2-1-反卷积" class="headerlink" title="2.1 反卷积"></a>2.1 反卷积</h3><p>下图为<code>stride=1、paddding=0</code>的反卷积的工作过程<br><img src="https://img-blog.csdnimg.cn/c50c7c3bebd142d48d93551748d7fcf2.gif#pic_center" alt="在这里插入图片描述"></p>
<p>下图为<code>stride=2、padding=1</code>的反卷积的工作过程<br><img src="https://img-blog.csdnimg.cn/d241df84e06e4314a0ffe52a15eb4a88.gif#pic_center" alt="在这里插入图片描述"></p>
<p>根据<strong>卷积</strong>的尺寸计算公式</p>
<script type="math/tex; mode=display">o=\frac {i-k+2 \cdot p} {s} + 1</script><p>得<strong>反卷积</strong>的尺寸就算公式为：</p>
<script type="math/tex; mode=display">i = (o-1) \cdot s + k - 2 \cdot p</script><p><strong>Pytorch实现</strong>：<a href="https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html?highlight=nn%20convtranspose2d#torch.nn.ConvTranspose2d">nn.ConvTranspose2d</a></p>
<h3 id="2-2-插值"><a href="#2-2-插值" class="headerlink" title="2.2 插值"></a>2.2 <a href="https://blog.csdn.net/qq_42735631/article/details/117751529">插值</a></h3><h4 id="2-2-1-最近邻插值"><a href="#2-2-1-最近邻插值" class="headerlink" title="2.2.1 最近邻插值"></a>2.2.1 最近邻插值</h4><p><img src="https://img-blog.csdnimg.cn/c3b2878c047a49d599dc626a8b30ae6d.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5L2V5aaC5Y2D5rO3,size_12,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<p>计算<strong>P</strong>与<strong>Q11、Q12、Q22、Q21</strong>的<strong>距离</strong>，<strong>可知P与Q11最近，所以P像素点的值与Q11像素点的值一样</strong></p>
<h4 id="2-2-2-双线性插值"><a href="#2-2-2-双线性插值" class="headerlink" title="2.2.2 双线性插值"></a>2.2.2 双线性插值</h4><p><img src="https://img-blog.csdnimg.cn/67e57649e93249488cb3b22d58a265d4.png#pic_center" alt="在这里插入图片描述"></p>
<p>双线性插值就是做两次线性变换，先在<strong>X</strong>轴上做一次线性变换，求出每一行的<strong>R</strong>点</p>
<script type="math/tex; mode=display">R_1=\frac {x_2-x} {x_2-x_1} Q_{11} + \frac {x-x_1} {x_2-x_1}Q_{21} \\ R_2=\frac {x_2-x} {x_2-x_1} Q_{12} + \frac {x-x_1} {x_2-x_1} Q_{22}</script><p>再在<strong>Y</strong>轴上做一次线性变换，求该区域的<strong>P</strong>点</p>
<script type="math/tex; mode=display">P=\frac {y_2-y} {y_2-y_1}R_1 + \frac {y-y_1} {y_2-y_1}R_2</script><h3 id="2-3-UpPooling"><a href="#2-3-UpPooling" class="headerlink" title="2.3 UpPooling"></a>2.3 <a href="https://pytorch.org/docs/stable/generated/torch.nn.MaxUnpool2d.html?highlight=nn%20unpool#torch.nn.MaxUnpool2d">UpPooling</a></h3><p><img src="https://img-blog.csdnimg.cn/ada957a8efea4989a4c96c3a57b5ef6f.png#pic_center" alt="在这里插入图片描述"></p>
<h3 id="2-4-Upsample"><a href="#2-4-Upsample" class="headerlink" title="2.4 Upsample"></a>2.4 <a href="https://pytorch.org/docs/stable/generated/torch.nn.Upsample.html">Upsample</a></h3><h2 id="3-跳跃结构"><a href="#3-跳跃结构" class="headerlink" title="3. 跳跃结构"></a>3. 跳跃结构</h2><p>如果<strong>直接用全卷积后的层进行上采样的话，得到的结果往往不够精细</strong>，所以本文中采取了跳级结构的方法，<strong>将更靠前的卷积层和经过上采样的层相结合</strong>，如下图所示：<br><img src="https://img-blog.csdnimg.cn/fdd748ead141469b9837c157e3d89fe3.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5L2V5aaC5Y2D5rO3,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<p>采用这种方法，能够<strong>在保留全局特征的前提下，尽可能使得图像的划分更为精细</strong></p>
]]></content>
      <categories>
        <category>图像分割</category>
      </categories>
      <tags>
        <tag>模型</tag>
        <tag>图像分割</tag>
      </tags>
  </entry>
  <entry>
    <title>Activation</title>
    <url>/2022/08/30/Activation/</url>
    <content><![CDATA[<h1 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h1><p>如果不用激活函数，每一层输出都是上层输入的线性函数，无论神经网络有多少层，最终的输出都是输入的线性组合。<br>激活函数给神经元引入了非线性因素，使得神经网络可以任意逼近任何非线性函数。<br><span id="more"></span></p>
<h2 id="1-激活函数的种类"><a href="#1-激活函数的种类" class="headerlink" title="1. 激活函数的种类"></a>1. 激活函数的种类</h2><h3 id="1-sigmoid"><a href="#1-sigmoid" class="headerlink" title="1. sigmoid"></a>1. sigmoid</h3><p>函数定义：</p>
<script type="math/tex; mode=display">{ f }(x)=\sigma (x)=\frac { 1 }{ 1+{ e }^{ -x } }</script><p>导数：</p>
<script type="math/tex; mode=display">{ f }^{ ' }(x)=f(x)(1-f(x))</script><p>优点：</p>
<ol>
<li>$sigmoid$ 函数的输出映射在 $(0,1)$ 之间，单调连续，输出范围有限，优化稳定，可以用作输出层；</li>
<li>求导容易；</li>
</ol>
<p>缺点：</p>
<ol>
<li>由于其软饱和性，一旦落入饱和区梯度就会接近于0，根据反向传播的链式法则，容易产生梯度消失，导致训练出现问题；</li>
<li>Sigmoid函数的输出恒大于0。非零中心化的输出会使得其后一层的神经元的输入发生偏置偏移（Bias Shift），并进一步使得梯度下降的收敛速度变慢；</li>
<li>计算时，由于具有幂运算，计算复杂度较高，运算速度较慢。</li>
</ol>
<h3 id="2-tanh"><a href="#2-tanh" class="headerlink" title="2. tanh"></a>2. tanh</h3><p>函数定义：</p>
<script type="math/tex; mode=display">{ f }(x)=tanh(x)=\frac { { e }^{ x }-{ e }^{ -x } }{ { e }^{ x }+{ e }^{ -x } }</script><p>导数：</p>
<script type="math/tex; mode=display">{ f }^{ ' }(x)=1-f(x)^{ 2 }</script><p>优点：</p>
<ol>
<li>$tanh$ 比 $sigmoid$ 函数收敛速度更快；</li>
<li>相比 $sigmoid$ 函数，$tanh$ 是以 $0$ 为中心的；</li>
</ol>
<p>缺点：</p>
<ol>
<li>与 $sigmoid$ 函数相同，由于饱和性容易产生的梯度消失；</li>
<li>与 $sigmoid$ 函数相同，由于具有幂运算，计算复杂度较高，运算速度较慢。</li>
</ol>
<h3 id="3-ReLU"><a href="#3-ReLU" class="headerlink" title="3. ReLU"></a>3. ReLU</h3><p>函数定义：</p>
<script type="math/tex; mode=display">f(x)=\begin{cases} \begin{matrix} 0 & x<0 \end{matrix} \\ \begin{matrix} x & x\ge 0 \end{matrix} \end{cases}</script><p>导数：</p>
<script type="math/tex; mode=display">{ { f }(x) }^{ ' }=\begin{cases} \begin{matrix} 0 & x<0 \end{matrix} \\ \begin{matrix} 1 & x\ge 0 \end{matrix} \end{cases}</script><p>优点：</p>
<ol>
<li>收敛速度快；</li>
<li>相较于 $sigmoid$ 和 $tanh$ 中涉及了幂运算，导致计算复杂度高， ReLU​可以更加简单的实现；</li>
<li>当输入 $x&gt;=0$ 时，ReLU​ 的导数为常数，这样可有效缓解梯度消失问题；</li>
<li>当 $x&lt;0$ 时，ReLU​ 的梯度总是 $0$，提供了神经网络的稀疏表达能力；</li>
</ol>
<p>缺点：</p>
<ol>
<li>ReLU​ 的输出不是以 $0$ 为中心的；</li>
<li>神经元坏死现象，某些神经元可能永远不会被激活，导致相应参数永远不会被更新；</li>
<li>不能避免梯度爆炸问题；</li>
</ol>
<h3 id="4-LReLU"><a href="#4-LReLU" class="headerlink" title="4. LReLU"></a>4. LReLU</h3><p>函数定义：</p>
<script type="math/tex; mode=display">f(x)=\begin{cases} \begin{matrix} \alpha x & x<0 \end{matrix} \\ \begin{matrix} x & x\ge 0 \end{matrix} \end{cases}</script><p>导数：</p>
<script type="math/tex; mode=display">{ { f }(x) }^{ ' }=\begin{cases} \begin{matrix} \alpha & x<0 \end{matrix} \\ \begin{matrix} 1 & x\ge 0 \end{matrix} \end{cases}</script><p>其中，$\alpha$ 常设置为0.01。函数图如 <strong>图6</strong> 所示：</p>
<p>优点：</p>
<ol>
<li>避免梯度消失；</li>
<li>由于导数总是不为零，因此可减少死神经元的出现；</li>
</ol>
<p>缺点：</p>
<ol>
<li>LReLU​ 表现并不一定比 ReLU​ 好；</li>
<li>无法避免梯度爆炸问题；</li>
</ol>
<h3 id="5-PReLU"><a href="#5-PReLU" class="headerlink" title="5. PReLU"></a>5. PReLU</h3><p>函数定义：</p>
<script type="math/tex; mode=display">f(\alpha ,x)=\begin{cases} \begin{matrix} \alpha x  & x<0 \end{matrix} \\ \begin{matrix} x & x\ge 0 \end{matrix} \end{cases}</script><p>导数：</p>
<script type="math/tex; mode=display">{ { f }(\alpha ,x) }^{ ' }=\begin{cases} \begin{matrix} \alpha  & x<0 \end{matrix} \\ \begin{matrix} 1 & x\ge 0 \end{matrix} \end{cases}</script><p>优点：</p>
<ol>
<li>PReLU​ 是 LReLU 的改进，可以自适应地从数据中学习参数；</li>
<li>收敛速度快、错误率低；</li>
<li>PReLU 可以用于反向传播的训练，可以与其他层同时优化；</li>
</ol>
<h3 id="6-RReLU"><a href="#6-RReLU" class="headerlink" title="6. RReLU"></a>6. RReLU</h3><p>函数定义：</p>
<script type="math/tex; mode=display">f(\alpha ,x)=\begin{cases} \begin{matrix} \alpha  & x<0 \end{matrix} \\ \begin{matrix} x & x\ge 0 \end{matrix} \end{cases}</script><p>导数：</p>
<script type="math/tex; mode=display">{ { f }(\alpha ,x) }^{ ' }=\begin{cases} \begin{matrix} \alpha  & x<0 \end{matrix} \\ \begin{matrix} 1 & x\ge 0 \end{matrix} \end{cases}</script><p>优点：为负值输入添加了一个线性项，这个线性项的斜率在每一个节点上都是随机分配的（通常服从均匀分布）。</p>
<h3 id="7-ELU"><a href="#7-ELU" class="headerlink" title="7. ELU"></a>7. ELU</h3><p>函数定义：</p>
<script type="math/tex; mode=display">f(\alpha ,x)=\begin{cases} \begin{matrix} \alpha \left( { e }^{ x }-1 \right)  & x<0 \end{matrix} \\ \begin{matrix} x & x\ge 0 \end{matrix} \end{cases}</script><p>导数：</p>
<script type="math/tex; mode=display">{ { f }(\alpha ,x) }^{ ' }=\begin{cases} \begin{matrix} f(\alpha ,x)+\alpha  & x<0 \end{matrix} \\ \begin{matrix} 1 & x\ge 0 \end{matrix} \end{cases}</script><p>优点：</p>
<ol>
<li>导数收敛为零，从而提高学习效率；</li>
<li>能得到负值输出，这能帮助网络向正确的方向推动权重和偏置变化；</li>
<li>防止死神经元出现。</li>
</ol>
<p>缺点：</p>
<ol>
<li>计算量大，其表现并不一定比 ReLU 好；</li>
<li>无法避免梯度爆炸问题；</li>
</ol>
<h3 id="8-SELU"><a href="#8-SELU" class="headerlink" title="8. SELU"></a>8. SELU</h3><p>函数定义：</p>
<script type="math/tex; mode=display">f(\alpha ,x)=\lambda \begin{cases} \begin{matrix} \alpha \left( { e }^{ x }-1 \right)  & x<0 \end{matrix} \\ \begin{matrix} x & x\ge 0 \end{matrix} \end{cases}</script><p>导数：</p>
<script type="math/tex; mode=display">{ { f }(\alpha ,x) }^{ ' }=\lambda \begin{cases} \begin{matrix} \alpha \left( { e }^{ x } \right)  & x<0 \end{matrix} \\ \begin{matrix} 1 & x\ge 0 \end{matrix} \end{cases}</script><p>优点：</p>
<ol>
<li>SELU 是 ELU 的一个变种。其中 λ 和 α 是固定数值（分别为 $1.0507$ 和 $1.6726$）;</li>
<li>经过该激活函数后使得样本分布自动归一化到 $0$ 均值和单位方差;</li>
<li>不会出现梯度消失或爆炸问题;</li>
</ol>
<h3 id="9-softsign"><a href="#9-softsign" class="headerlink" title="9. softsign"></a>9. softsign</h3><p>函数定义：</p>
<script type="math/tex; mode=display">f(x)=\frac { x }{ \left| x \right| +1 }</script><p>导数：</p>
<script type="math/tex; mode=display">{ f }^{ ' }(x)=\frac { 1 }{ { (1+\left| x \right| ) }^{ 2 } }</script><p>优点：</p>
<ol>
<li>$softsign$ 是 $tanh$ 激活函数的另一个替代选择；</li>
<li>$softsign$ 是反对称、去中心、可微分，并返回 $-1$ 和 $1$ 之间的值；</li>
<li>$softsign$ 更平坦的曲线与更慢的下降导数表明它可以更高效地学习；</li>
</ol>
<p>缺点：</p>
<ol>
<li>导数的计算比$tanh$ 更麻烦；</li>
</ol>
<h3 id="10-softplus"><a href="#10-softplus" class="headerlink" title="10. softplus"></a>10. softplus</h3><p>函数定义：</p>
<script type="math/tex; mode=display">f(x)=\ln { (1+{ e }^{ x }) }</script><p>导数：</p>
<script type="math/tex; mode=display">{ f }^{ ' }(x)=\frac { 1 }{ 1+{ e }^{ -x } }</script><p>优点：</p>
<ol>
<li>作为 $relu$ 的一个不错的替代选择，$softplus$ 能够返回任何大于 $0$ 的值。</li>
<li>与 $relu$ 不同，$softplus$ 的导数是连续的、非零的，无处不在，从而防止出现死神经元。</li>
</ol>
<p>缺点：</p>
<ol>
<li>导数常常小于 $1$ ，也可能出现梯度消失的问题。</li>
<li>$softplus$ 另一个不同于 $relu$ 的地方在于其不对称性，不以零为中心，可能会妨碍学习。</li>
</ol>
<h3 id="11-softmax"><a href="#11-softmax" class="headerlink" title="11. softmax"></a>11. softmax</h3><p>softmax 函数一般用于多分类问题中，它是对逻辑斯蒂（logistic）回归的一种推广，也被称为多项逻辑斯蒂回归模型(multi-nominal logistic mode)。假设要实现 k 个类别的分类任务，Softmax 函数将输入数据 $x_i$ 映射到第 $i$ 个类别的概率 $y_i$ 如下计算：</p>
<script type="math/tex; mode=display">
y_i=soft\max \left( x_i \right) =\frac{e^{x_i}}{\sum_{j=1}^k{e^{x_j}}}</script><h3 id="12-swish"><a href="#12-swish" class="headerlink" title="12. swish"></a>12. swish</h3><p>函数定义：</p>
<script type="math/tex; mode=display">f\left( x \right) =x\cdot \sigma \left( x \right)</script><p>其中，$\sigma$ 是 $sigmoid$ 函数。</p>
<p>$swish$ 激活函数的一阶导数如下：</p>
<script type="math/tex; mode=display">\begin{array}{c}
    f^{'}\left( x \right) =\sigma \left( x \right) +x\cdot \sigma \left( x \right) \left( 1-\sigma \left( x \right) \right)\\
    =\sigma \left( x \right) +x\cdot \sigma \left( x \right) -x\cdot \sigma \left( x \right) ^2\\
    =x\cdot \sigma \left( x \right) +\sigma \left( x \right) \left( 1-x\cdot \sigma \left( x \right) \right)\\
    =f\left( x \right) +\sigma \left( x \right) \left( 1-f\left( x \right) \right)\\
\end{array}</script><p>超参数版 $swish$ 激活函数：</p>
<script type="math/tex; mode=display">f\left( x \right) =x\cdot \sigma \left( \beta x \right)</script><p>其中，$\beta$ 是超参数。超参数版 $swish$ 激活函数的图形如 <strong>图16</strong> 所示：</p>
<p>优点：</p>
<ol>
<li>当 $x&gt;0$ 时，不存在梯度消失的情况；当 $x&lt;0$ 时，神经元也不会像 ReLU 一样出现死亡的情况；</li>
<li>$swish$ 处处可导，连续光滑；</li>
<li>$swish$ 并非一个单调的函数；</li>
<li>提升了模型的性能；</li>
</ol>
<p>缺点：</p>
<ol>
<li>计算量大；</li>
</ol>
<h3 id="13-hswish"><a href="#13-hswish" class="headerlink" title="13. hswish"></a>13. hswish</h3><p>函数定义：</p>
<script type="math/tex; mode=display">f\left( x \right) =x\frac{\text{Re}LU6\left( x+3 \right)}{6}</script><p>优点：<br>与 $swish$ 相比 $hard \ swish$ 减少了计算量，具有和 $swish$ 同样的性质。</p>
<p>缺点：<br>与 $relu6$ 相比 $hard \ swish$ 的计算量仍然较大。</p>
<h2 id="2-激活函数的选择"><a href="#2-激活函数的选择" class="headerlink" title="2. 激活函数的选择"></a>2. 激活函数的选择</h2><ol>
<li>浅层网络在分类器时，$sigmoid$ 函数及其组合通常效果更好。</li>
<li>由于梯度消失问题，有时要避免使用 $sigmoid$ 和 $tanh$ 函数。</li>
<li>$relu$ 函数是一个通用的激活函数，目前在大多数情况下使用。</li>
<li>如果神经网络中出现死神经元，那么 $prelu$ 函数就是最好的选择。</li>
<li>$relu$ 函数只能在隐藏层中使用。</li>
<li>通常，可以从 $relu$ 函数开始，如果 $relu$ 函数没有提供最优结果，再尝试其他激活函数。</li>
</ol>
<h2 id="3-激活函数相关问题"><a href="#3-激活函数相关问题" class="headerlink" title="3. 激活函数相关问题"></a>3. 激活函数相关问题</h2><blockquote>
<p>为什么 $relu$ 不是全程可微/可导也能用于基于梯度的学习？</p>
</blockquote>
<p>从数学的角度看 $relu$ 在 $0$ 点不可导，因为它的左导数和右导数不相等；但在实现时通常会返回左导数或右导数的其中一个，而不是报告一个导数不存在的错误，从而避免了这个问题。</p>
<blockquote>
<p>为什么 $tanh$ 的收敛速度比 $sigmoid$ 快？</p>
</blockquote>
<script type="math/tex; mode=display">\tan\text{h}^{'}\left( x \right) =1-\tan\text{h}\left( x \right) ^2\in \left( 0,1 \right)</script><script type="math/tex; mode=display">s^{'}\left( x \right) =s\left( x \right) \left( 1-s\left( x \right) \right) \in \left( 0,\frac{1}{4} \right]</script><p>由上面两个公式可知 $tanh$ 引起的梯度消失问题没有 $sigmoid$ 严重，所以 $tanh$ 收敛速度比 $sigmoid$ 快。</p>
<blockquote>
<p>sigmoid 和 softmax 有什么区别？</p>
</blockquote>
<ol>
<li>二分类问题时 $sigmoid$ 和 $softmax$ 是一样的，都是求 $cross \ entropy \ loss$ ，而 $softmax$ 可以用于多分类问题。</li>
<li>$softmax$ 是 $sigmoid$ 的扩展，因为，当类别数 $k=2$ 时，$softmax$ 回归退化为 $logistic$ 回归。</li>
<li>$softmax$ 建模使用的分布是多项式分布，而 $logistic$ 则基于伯努利分布。</li>
<li>多个 $logistic$ 回归通过叠加也同样可以实现多分类的效果，但是 $softmax$ 回归进行的多分类，类与类之间是互斥的，即一个输入只能被归为一类；多 $logistic$ 回归进行多分类，输出的类别并不是互斥的。</li>
</ol>
]]></content>
      <categories>
        <category>深度学习基础</category>
      </categories>
      <tags>
        <tag>激活函数</tag>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title>Happy</title>
    <url>/2022/09/01/Happy/</url>
    <content><![CDATA[<blockquote>
<p>好剧分享，快乐一下</p>
</blockquote>
<span id="more"></span>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src=https://img1.baidu.com/it/u=3537231667,2941555870&fm=253&fmt=auto&app=138&f=JPEG?w=379&h=500 width = "30%" alt=""/>
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">
    <a href="https://www.bilibili.com/bangumi/play/ep473306?from_spmid=666.19.0.0">机智的监狱生活</a>
    </div>
</center>

<hr>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src=https://www.kan.cc/uploads/allimg/202207/37b1c03158542032.jpg width = "30%" alt=""/>
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">
    <a href="https://www.kan.cc/view/3651.html">黑话律师</a>
    </div>
</center>

<hr>
]]></content>
      <categories>
        <category>娱乐</category>
      </categories>
  </entry>
  <entry>
    <title>DeepLab</title>
    <url>/2022/06/17/DeepLab/</url>
    <content><![CDATA[<h1 id="DeepLab系列"><a href="#DeepLab系列" class="headerlink" title="DeepLab系列"></a>DeepLab系列</h1><blockquote>
<p>本文介绍了DeepLabV1、DeepLabV2、DeepLabV3和DeepLabV3+四种模型，并使用Pytorch进行了实现。<br><span id="more"></span></p>
</blockquote>
<h2 id="1-DeepLabV1"><a href="#1-DeepLabV1" class="headerlink" title="1. DeepLabV1"></a>1. DeepLabV1</h2><h3 id="1-1-语义分割中存在的问题"><a href="#1-1-语义分割中存在的问题" class="headerlink" title="1.1 语义分割中存在的问题"></a>1.1 语义分割中存在的问题</h3><p><strong>1. 信号下采样导致分辨率降低</strong></p>
<ul>
<li>造成原因：采用<code>MaxPooling</code>造成的</li>
<li>解决办法：引入<code>atrous Conv</code>空洞卷积</li>
</ul>
<p><strong>2. CNN的空间不变性</strong></p>
<ul>
<li>造成原因：重复的池化和下采样</li>
<li>解决办法：使用<code>DenseCRF</code></li>
</ul>
<h3 id="1-2-空洞卷积"><a href="#1-2-空洞卷积" class="headerlink" title="1.2 空洞卷积"></a>1.2 空洞卷积</h3><p>空洞卷积通过引入扩张率<code>Dilation Rate</code>这一参数使得同样尺寸的卷积核获得更大的感受野</p>
<p><strong>1. 扩张率为1的3*3卷积，其与标准卷积一样</strong><br><img src="https://img-blog.csdnimg.cn/31476414ebdc41c68c896051c1c83e18.png#pic_center" alt="在这里插入图片描述"></p>
<p><strong>2. 扩张率为2的3*3卷积</strong><br><img src="https://img-blog.csdnimg.cn/fbe8fc72eca34ab6ab9a4b205c2b2d8a.png#pic_center" alt="在这里插入图片描述"></p>
<p><strong>3. 扩张率为4的3*3卷积</strong><br><img src="https://img-blog.csdnimg.cn/e03b1634326e46b39c5d68231e612ec4.png#pic_center" alt="在这里插入图片描述"></p>
<h3 id="1-3-网络结构"><a href="#1-3-网络结构" class="headerlink" title="1.3 网络结构"></a>1.3 网络结构</h3><p><strong>使用VGG16模型作为backbone</strong></p>
<ul>
<li>将VGG16中的全连接层转化为卷积层</li>
<li>将VGG16中的<code>MaxPooling</code>层由<code>kernel=2, stride=2</code>转化为<code>kernel=3, stride=2, padding=1</code>，并且最后两个<code>MaxPooling</code>层的<code>stride</code>全部设置为<code>1</code></li>
<li>将VGG16中的最后三个卷积层修改为空洞卷积，扩张率为2；并且第一个全连接层卷积化也修改为空洞卷积，在论文中<code>LargeFOV</code>中的设置为<code>12</code></li>
</ul>
<p><strong>Pytorch实现</strong><br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># !/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*-coding:utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"># File       : backbone.py</span></span><br><span class="line"><span class="string"># Author     ：CodeCat</span></span><br><span class="line"><span class="string"># version    ：python 3.7</span></span><br><span class="line"><span class="string"># Software   ：Pycharm</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">conv3x3</span>(<span class="params">in_channels, out_channels, stride=<span class="number">1</span>, dilation=<span class="number">1</span>, padding=<span class="number">1</span></span>):</span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">        nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">3</span>, stride=stride, padding=padding, dilation=dilation),</span><br><span class="line">        nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">conv1x1</span>(<span class="params">in_channels, out_channels, stride=<span class="number">1</span>, dilation=<span class="number">1</span>, padding=<span class="number">1</span></span>):</span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">        nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">1</span>, stride=stride, padding=padding, dilation=dilation),</span><br><span class="line">        nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Block</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels, num_depth=<span class="number">2</span>, padding=<span class="number">1</span>, dilation=<span class="number">1</span>, pool_stride=<span class="number">2</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Block, self).__init__()</span><br><span class="line">        self.num_depth = num_depth</span><br><span class="line">        self.conv1 = conv3x3(in_channels, out_channels, padding=padding, dilation=dilation)</span><br><span class="line">        self.conv2 = conv3x3(out_channels, out_channels, padding=padding, dilation=dilation)</span><br><span class="line">        <span class="keyword">if</span> self.num_depth == <span class="number">3</span>:</span><br><span class="line">            self.conv3 = conv3x3(out_channels, out_channels, padding=padding, dilation=dilation)</span><br><span class="line">        self.pool = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=pool_stride, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        x = self.conv2(x)</span><br><span class="line">        <span class="keyword">if</span> self.num_depth == <span class="number">3</span>:</span><br><span class="line">            x = self.conv3(x)</span><br><span class="line">        x = self.pool(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DeepLabV1</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes=<span class="number">21</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(DeepLabV1, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.block1 = Block(in_channels=<span class="number">3</span>, out_channels=<span class="number">64</span>)</span><br><span class="line">        self.block2 = Block(in_channels=<span class="number">64</span>, out_channels=<span class="number">128</span>)</span><br><span class="line">        self.block3 = Block(in_channels=<span class="number">128</span>, out_channels=<span class="number">256</span>, num_depth=<span class="number">3</span>)</span><br><span class="line">        self.block4 = Block(in_channels=<span class="number">256</span>, out_channels=<span class="number">512</span>, num_depth=<span class="number">3</span>, pool_stride=<span class="number">1</span>)</span><br><span class="line">        self.block5 = Block(in_channels=<span class="number">512</span>, out_channels=<span class="number">512</span>, num_depth=<span class="number">3</span>, pool_stride=<span class="number">1</span>, dilation=<span class="number">2</span>, padding=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        self.avg_pool = nn.AvgPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        self.conv6 = conv3x3(in_channels=<span class="number">512</span>, out_channels=<span class="number">1024</span>, padding=<span class="number">12</span>, dilation=<span class="number">12</span>)</span><br><span class="line">        self.drop6 = nn.Dropout2d(p=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">        self.conv7 = conv1x1(in_channels=<span class="number">1024</span>, out_channels=<span class="number">1024</span>, padding=<span class="number">0</span>)</span><br><span class="line">        self.drop7 = nn.Dropout2d(p=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">        self.conv8 = conv1x1(in_channels=<span class="number">1024</span>, out_channels=num_classes, padding=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        input_size = x.shape[-<span class="number">2</span>:]</span><br><span class="line">        <span class="comment"># (b, 3, 224, 224) -&gt; (b, 64, 112, 112)</span></span><br><span class="line">        x = self.block1(x)</span><br><span class="line">        <span class="comment"># (b, 64, 112, 112) -&gt; (b, 128, 56, 56)</span></span><br><span class="line">        x = self.block2(x)</span><br><span class="line">        <span class="comment"># (b, 128, 56, 56) -&gt; (b, 256, 28, 28)</span></span><br><span class="line">        x = self.block3(x)</span><br><span class="line">        <span class="comment"># (b, 256, 28, 28) -&gt; (b, 512, 28, 28)</span></span><br><span class="line">        x = self.block4(x)</span><br><span class="line">        <span class="comment"># (b, 512, 28, 28) -&gt; (b, 512, 28, 28)</span></span><br><span class="line">        x = self.block5(x)</span><br><span class="line">        <span class="comment"># (b, 512, 28, 28) -&gt; (b, 512, 28, 28)</span></span><br><span class="line">        x = self.avg_pool(x)</span><br><span class="line">        <span class="comment"># (b, 512, 28, 28) -&gt; (b, 1024, 28, 28)</span></span><br><span class="line">        x = self.conv6(x)</span><br><span class="line">        x = self.drop6(x)</span><br><span class="line">        <span class="comment"># (b, 1024, 28, 28) -&gt; (b, 1024, 28, 28)</span></span><br><span class="line">        x = self.conv7(x)</span><br><span class="line">        x = self.drop7(x)</span><br><span class="line">        <span class="comment"># (b, 1024, 28, 28) -&gt; (b, num_classes, 28, 28)</span></span><br><span class="line">        x = self.conv8(x)</span><br><span class="line">        <span class="comment"># (b, num_classes, 28, 28) -&gt; (b, num_classes, 224, 224)</span></span><br><span class="line">        x = F.interpolate(x, size=input_size, mode=<span class="string">&#x27;bilinear&#x27;</span>, align_corners=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    model = DeepLabV1()</span><br><span class="line">    inputs = torch.randn(<span class="number">2</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>)</span><br><span class="line">    outputs = model(inputs)</span><br><span class="line">    <span class="built_in">print</span>(outputs.shape)</span><br></pre></td></tr></table></figure></p>
<h2 id="2-DeepLabV2"><a href="#2-DeepLabV2" class="headerlink" title="2. DeepLabV2"></a>2. DeepLabV2</h2><h3 id="2-1-语义分割中存在的问题"><a href="#2-1-语义分割中存在的问题" class="headerlink" title="2.1 语义分割中存在的问题"></a>2.1 语义分割中存在的问题</h3><ol>
<li>分辨率被降低导致特征层丢失细节信息：主要由于下采样<code>stride&gt;1</code>的层造成的</li>
<li>目标的多尺度问题</li>
<li>DCNNs的不变性会降低定位精度</li>
</ol>
<h3 id="2-1-论文中的解决办法"><a href="#2-1-论文中的解决办法" class="headerlink" title="2.1 论文中的解决办法"></a>2.1 论文中的解决办法</h3><ol>
<li>针对问题1，一般是将最后几个<code>MaxPooling</code>层的<code>stride</code>设置为1（若是通过卷积进行下采样，也是将其<code>stride</code>设置为1），然后再配合空洞卷积</li>
<li>针对问题2，本文提出了<code>ASPP</code>模块</li>
<li>针对问题3，和DeepLabV1一样采用<code>DenseCRF</code></li>
</ol>
<h3 id="2-3-ASPP模块"><a href="#2-3-ASPP模块" class="headerlink" title="2.3 ASPP模块"></a>2.3 ASPP模块</h3><p><strong>并行采用多个采样率的空洞卷积提取特征，再将特征进行融合，该结构称为空洞空间金字塔池化</strong><br><img src="https://img-blog.csdnimg.cn/c381fd7f04344a5da13c03ef66598439.png#pic_center" alt="在这里插入图片描述"></p>
<h3 id="2-4-网络结构"><a href="#2-4-网络结构" class="headerlink" title="2.4 网络结构"></a>2.4 网络结构</h3><p><strong>与DeepLabV1使用VGG16作为backbone不同的是，DeepLabV2使用ResNet101作为backbone，做出的修改如下：</strong></p>
<ol>
<li>将<code>Layer3</code>中的<code>Bottleneck1</code>中原本进行下采样的<code>3x3</code>卷积层(<code>stride=2</code>)的<code>stride</code>设置为<code>1</code>，即不进行下采样，并且<code>3x3</code>卷积层全部采用扩张率为<code>2</code>的空洞卷积</li>
<li>将<code>Layer4</code>中的<code>Bottleneck1</code>中原本进行下采样的<code>3x3</code>卷积层(<code>stride=2</code>)的<code>stride</code>设置为<code>1</code>，即不进行下采样，并且<code>3x3</code>卷积层全部采用扩张率为<code>4</code>的空洞卷积</li>
<li><code>ASPP</code>模块中的每一个分支只有一个<code>3x3</code>的空洞卷积层，并且卷积核的个数等于<code>num_classes</code></li>
</ol>
<p><strong>Pytorch实现</strong><br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># !/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*-coding:utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"># File       : backbone.py</span></span><br><span class="line"><span class="string"># Author     ：CodeCat</span></span><br><span class="line"><span class="string"># version    ：python 3.7</span></span><br><span class="line"><span class="string"># Software   ：Pycharm</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Bottleneck</span>(nn.Module):</span><br><span class="line">    expansion = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels, stride=<span class="number">1</span>, dilation=<span class="number">1</span>, downsample=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Bottleneck, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">1</span>, stride=stride, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(out_channels)</span><br><span class="line"></span><br><span class="line">        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=dilation, dilation=dilation, bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(out_channels)</span><br><span class="line"></span><br><span class="line">        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)</span><br><span class="line"></span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.downsample = downsample</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        identity = x</span><br><span class="line">        <span class="keyword">if</span> self.downsample <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            identity = self.downsample(x)</span><br><span class="line"></span><br><span class="line">        out = self.relu(self.bn1(self.conv1(x)))</span><br><span class="line"></span><br><span class="line">        out = self.relu(self.bn2(self.conv2(out)))</span><br><span class="line"></span><br><span class="line">        out = self.conv3(out)</span><br><span class="line">        out = self.bn3(out)</span><br><span class="line"></span><br><span class="line">        out += identity</span><br><span class="line">        out = self.relu(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ASPP</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels, atrous_rates</span>):</span><br><span class="line">        <span class="built_in">super</span>(ASPP, self).__init__()</span><br><span class="line">        <span class="keyword">for</span> i, rate <span class="keyword">in</span> <span class="built_in">enumerate</span>(atrous_rates):</span><br><span class="line">            self.add_module(<span class="string">&#x27;c%d&#x27;</span>%i, nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=rate, dilation=rate, bias=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">sum</span>([stage(x) <span class="keyword">for</span> stage <span class="keyword">in</span> self.children()])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DeepLabV2</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes, block_nums, atrous_rates</span>):</span><br><span class="line">        <span class="built_in">super</span>(DeepLabV2, self).__init__()</span><br><span class="line">        self.in_channels = <span class="number">64</span></span><br><span class="line"></span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, self.in_channels, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(self.in_channels)</span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.maxpool = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        self.layer1 = self._make_layer(<span class="number">64</span>, block_nums[<span class="number">0</span>])</span><br><span class="line">        self.layer2 = self._make_layer(<span class="number">128</span>, block_nums[<span class="number">1</span>], stride=<span class="number">2</span>)</span><br><span class="line">        self.layer3 = self._make_layer(<span class="number">256</span>, block_nums[<span class="number">2</span>], dilation=<span class="number">2</span>)</span><br><span class="line">        self.layer4 = self._make_layer(<span class="number">512</span>, block_nums[<span class="number">3</span>], dilation=<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">        self.aspp = ASPP(in_channels=<span class="number">512</span> * Bottleneck.expansion, out_channels=num_classes, atrous_rates=atrous_rates)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        input_size = x.shape[-<span class="number">2</span>:]</span><br><span class="line">        <span class="comment"># (b, 3, 224, 224) -&gt; (b, 64, 112, 112)</span></span><br><span class="line">        x = self.relu(self.bn1(self.conv1(x)))</span><br><span class="line">        <span class="comment"># (b, 64, 112, 112) -&gt; (b, 64, 56, 56)</span></span><br><span class="line">        x = self.maxpool(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># (b, 64, 56, 56) -&gt; (b, 256, 56, 56)</span></span><br><span class="line">        x = self.layer1(x)</span><br><span class="line">        <span class="comment"># (b, 256, 56, 56) -&gt; (b, 512, 28, 28)</span></span><br><span class="line">        x = self.layer2(x)</span><br><span class="line">        <span class="comment"># (b, 512, 28, 28) -&gt; (b, 1024, 28, 28)</span></span><br><span class="line">        x = self.layer3(x)</span><br><span class="line">        <span class="comment"># (b, 1024, 28, 28) -&gt; (b, 2048, 28, 28)</span></span><br><span class="line">        x = self.layer4(x)</span><br><span class="line">        <span class="comment"># (b, 2048, 28, 28) -&gt; (b, num_classes, 28, 28)</span></span><br><span class="line">        x = self.aspp(x)</span><br><span class="line">        <span class="comment"># (b, num_classes, 28, 28) -&gt; (b, num_classes, 224, 224)</span></span><br><span class="line">        x = F.interpolate(x, size=input_size, mode=<span class="string">&#x27;bilinear&#x27;</span>, align_corners=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_make_layer</span>(<span class="params">self, channels, block_num, stride=<span class="number">1</span>, dilation=<span class="number">1</span></span>):</span><br><span class="line">        downsample = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> stride != <span class="number">1</span> <span class="keyword">or</span> self.in_channels != channels * Bottleneck.expansion:</span><br><span class="line">            downsample = nn.Sequential(</span><br><span class="line">                nn.Conv2d(self.in_channels, channels * Bottleneck.expansion, kernel_size=<span class="number">1</span>, stride=stride, bias=<span class="literal">False</span>),</span><br><span class="line">                nn.BatchNorm2d(channels * Bottleneck.expansion)</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        layers = <span class="built_in">list</span>()</span><br><span class="line"></span><br><span class="line">        layers.append(Bottleneck(self.in_channels, channels, downsample=downsample, stride=stride, dilation=dilation))</span><br><span class="line">        self.in_channels = channels * Bottleneck.expansion</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, block_num):</span><br><span class="line">            layers.append(Bottleneck(self.in_channels, channels, dilation=dilation))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    model = DeepLabV2(</span><br><span class="line">        num_classes=<span class="number">21</span>,</span><br><span class="line">        block_nums=[<span class="number">3</span>, <span class="number">4</span>, <span class="number">23</span>, <span class="number">3</span>],</span><br><span class="line">        atrous_rates=[<span class="number">6</span>, <span class="number">12</span>, <span class="number">18</span>, <span class="number">24</span>]</span><br><span class="line">    )</span><br><span class="line">    inputs = torch.randn(<span class="number">2</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>)</span><br><span class="line">    outputs = model(inputs)</span><br><span class="line">    <span class="built_in">print</span>(outputs.shape)</span><br></pre></td></tr></table></figure></p>
<h2 id="3-DeepLabV3"><a href="#3-DeepLabV3" class="headerlink" title="3. DeepLabV3"></a>3. DeepLabV3</h2><p><strong>改进了ASPP模块</strong></p>
<h3 id="3-1-ASPP模块"><a href="#3-1-ASPP模块" class="headerlink" title="3.1 ASPP模块"></a>3.1 ASPP模块</h3><p><img src="https://img-blog.csdnimg.cn/img_convert/3adb3fe220965bd35443645f8d50fafb.png" alt=""></p>
<p><strong>ASPP模块</strong></p>
<ul>
<li>一个<code>1x1</code>卷积</li>
<li>三个<code>3x3</code>空洞卷积，当<code>output_stride=16</code>时，<code>rates=(6, 12, 18)</code>；当<code>output_stride=8</code>时，扩张率翻倍，即<code>rates=(12, 24, 36)</code></li>
<li>图像级特征：将特征做全局平均池化，后<code>1x1</code>卷积，再上采样</li>
<li>每个卷积层后面会加入<code>BN</code>层</li>
</ul>
<p><strong><code>output_stride</code>说明</strong></p>
<ul>
<li>表示输入图像大小与输出特征图大小的比值</li>
<li>在图像分类任务中，最终的输出特征图比输入图像大小小32倍，即<code>output_stride=32</code></li>
<li>在语义分割任务中，<code>output_stride</code>一般为<code>8</code>或<code>16</code>，通常通过改变最后1个或2个block，使其不再缩小特征图的大小，并应用空洞卷积来密集提取特征<br><strong>Pytorch实现</strong><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ASPP</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels, rate=<span class="number">1</span>, bn_momentum=<span class="number">0.1</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(ASPP, self).__init__()</span><br><span class="line">        self.branch1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, out_channels, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), stride=<span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channels, momentum=bn_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">        self.branch2 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, out_channels, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=<span class="number">1</span>, padding=<span class="number">6</span>*rate, dilation=<span class="number">6</span>*rate),</span><br><span class="line">            nn.BatchNorm2d(out_channels, momentum=bn_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">        self.branch3 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, out_channels, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=<span class="number">1</span>, padding=<span class="number">12</span>*rate, dilation=<span class="number">12</span>*rate),</span><br><span class="line">            nn.BatchNorm2d(out_channels, momentum=bn_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">        self.branch4 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, out_channels, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=<span class="number">1</span>, padding=<span class="number">18</span>*rate, dilation=<span class="number">18</span>*rate),</span><br><span class="line">            nn.BatchNorm2d(out_channels, momentum=bn_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">        self.branch5 = nn.Sequential(</span><br><span class="line">            nn.AdaptiveAvgPool2d(output_size=(<span class="number">1</span>, <span class="number">1</span>)),</span><br><span class="line">            nn.Conv2d(in_channels, out_channels, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), stride=<span class="number">1</span>, padding=<span class="number">0</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channels, momentum=bn_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.conv_cat = nn.Sequential(</span><br><span class="line">            nn.Conv2d(out_channels*<span class="number">5</span>, out_channels, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), stride=<span class="number">1</span>, padding=<span class="number">0</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channels, momentum=bn_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        b, c, h, w = x.size()</span><br><span class="line"></span><br><span class="line">        conv1x1 = self.branch1(x)</span><br><span class="line">        conv3x3_1 = self.branch2(x)</span><br><span class="line">        conv3x3_2 = self.branch3(x)</span><br><span class="line">        conv3x3_3 = self.branch4(x)</span><br><span class="line"></span><br><span class="line">        global_feature = self.branch5(x)</span><br><span class="line">        global_feature = F.interpolate(global_feature, size=(h, w), mode=<span class="string">&#x27;bilinear&#x27;</span>, align_corners=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        feature_cat = torch.cat([conv1x1, conv3x3_1, conv3x3_2, conv3x3_3, global_feature], dim=<span class="number">1</span>)</span><br><span class="line">        result = self.conv_cat(feature_cat)</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    model = ASPP(in_channels=<span class="number">2048</span>, out_channels=<span class="number">2048</span>)</span><br><span class="line">    inputs = torch.randn(<span class="number">2</span>, <span class="number">2048</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">    outputs = model(inputs)</span><br><span class="line">    <span class="built_in">print</span>(outputs.shape)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="4-DeepLabV3"><a href="#4-DeepLabV3" class="headerlink" title="4. DeepLabV3+"></a>4. DeepLabV3+</h2><h3 id="4-1-简介"><a href="#4-1-简介" class="headerlink" title="4.1 简介"></a>4.1 简介</h3><p><strong>DeepLabV3+不仅采用了ASPP结构，而且还采用了编码器-解码器结构</strong></p>
<h3 id="4-2-网络结构"><a href="#4-2-网络结构" class="headerlink" title="4.2 网络结构"></a>4.2 网络结构</h3><p><img src="https://img-blog.csdnimg.cn/img_convert/68e93e65300bce0b7042a77ddcb20e90.png" alt=""><br>网络的<strong>编码器</strong>结构与<code>DeepLabV3</code>一样。<br><strong>解码器</strong>与<code>DeepLabV3</code>不一样，<code>DeepLabV3</code>以<code>factor=16</code>直接进行上采样，而<code>DeepLabV3+</code>采用层级解码器，不是一步到位的，而是通过如下步骤：</p>
<ul>
<li>首先将编码器提取的特征图进行<code>factor=4</code>的上采样，然后和尺寸相同的<code>low-level</code>特征进行<code>concat</code>拼接</li>
<li><code>low-level</code>特征首先采用<code>1x1</code>卷积进行降维，这样能够使得编码器提取的特征有一个偏重</li>
<li>最后再采用<code>3x3</code>卷积进一步提取特征，再以<code>factor=4</code>进行上采样</li>
</ul>
<hr>
<p><strong>完整代码：</strong> <a href="https://github.com/codecat0/CV/tree/main/Semantic_Segmentation/DeepLabV3%2B">https://github.com/codecat0/CV/tree/main/Semantic_Segmentation/DeepLabV3+</a></p>
]]></content>
      <categories>
        <category>图像分割</category>
      </categories>
      <tags>
        <tag>模型</tag>
        <tag>图像分割</tag>
      </tags>
  </entry>
  <entry>
    <title>SegNet</title>
    <url>/2021/12/31/SegNet/</url>
    <content><![CDATA[<h1 id="SegNet论文详解"><a href="#SegNet论文详解" class="headerlink" title="SegNet论文详解"></a>SegNet论文详解</h1><p>本文提出了一种用于语义分割的深度全卷积神经网络结构SegNet，其核心<strong>由一个编码器网络和一个对应的解码器网络以及一个像素级分类层组成</strong>。<br><span id="more"></span></p>
<p>本文的创新在于：<br>解码器使用在对应编码器的最大池化步骤中计算的<strong>池化索引</strong>来执行非线性上采样，这与反卷积相比，减少了参数量和运算量，而且消除了学习上采样的需要。<br><img src="https://img-blog.csdnimg.cn/0ed48fd837404b7da916fc0ed8d4cbf8.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5L2V5aaC5Y2D5rO3,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<h2 id="1-网络结构"><a href="#1-网络结构" class="headerlink" title="1. 网络结构"></a>1. 网络结构</h2><p><img src="https://img-blog.csdnimg.cn/28ab3c4e856447e4b981ecfdcad3055c.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5L2V5aaC5Y2D5rO3,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<h3 id="1-1-编码器"><a href="#1-1-编码器" class="headerlink" title="1.1 编码器"></a>1.1 编码器</h3><ol>
<li>Conv层<ul>
<li>通过卷积提取特征，其中使用的是<code>same padding</code>的卷积，不会改变特征图的尺寸</li>
</ul>
</li>
<li>BN层<ul>
<li>起到归一化的作用</li>
</ul>
</li>
<li>ReLU层<ul>
<li>起到激活函数的作用</li>
</ul>
</li>
<li>Pooling层<ul>
<li><code>max pooling</code>层，同时会<strong>记录最大值的索引位置</strong></li>
</ul>
</li>
</ol>
<h3 id="1-2-解码器"><a href="#1-2-解码器" class="headerlink" title="1.2 解码器"></a>1.2 解码器</h3><ol>
<li><p>Upsampling层<br><img src="https://img-blog.csdnimg.cn/0afcb64febd349909cc66e0ca58966fc.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5L2V5aaC5Y2D5rO3,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<ul>
<li>对输入的特征图放大两倍，然后把输入特征图的数据根据编码器<code>pooling</code>层的<strong>索引位置</strong>放入，<strong>其他位置为0</strong></li>
</ul>
</li>
<li>Conv层<ul>
<li>通过卷积提取特征，其中使用的是<code>same padding</code>的卷积，不会改变特征图的尺寸</li>
</ul>
</li>
<li>BN层<ul>
<li>起到归一化的作用</li>
</ul>
</li>
<li>ReLU层<ul>
<li>起到激活函数的作用</li>
</ul>
</li>
</ol>
<h3 id="1-3-像素级分类层"><a href="#1-3-像素级分类层" class="headerlink" title="1.3 像素级分类层"></a>1.3 像素级分类层</h3><p>输出每一个像素点在所有类别概率，其中<strong>最大的概率类别为该像素的预测值</strong></p>
<h2 id="2-Pytorch实现"><a href="#2-Pytorch实现" class="headerlink" title="2. Pytorch实现"></a>2. Pytorch实现</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Encoder</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels</span>):</span><br><span class="line">        <span class="built_in">super</span>(Encoder, self).__init__()</span><br><span class="line"></span><br><span class="line">        batchNorm_momentum = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line">        self.encode1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, <span class="number">64</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">64</span>, momentum=batchNorm_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">64</span>, momentum=batchNorm_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.encode2 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">64</span>, <span class="number">128</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">128</span>, momentum=batchNorm_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">128</span>, <span class="number">128</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">128</span>, momentum=batchNorm_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.encode3 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">128</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">256</span>, momentum=batchNorm_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">256</span>, momentum=batchNorm_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.encode4 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">256</span>, <span class="number">512</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">512</span>, momentum=batchNorm_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">512</span>, momentum=batchNorm_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.encode5 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">512</span>, momentum=batchNorm_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">512</span>, momentum=batchNorm_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        idx = []</span><br><span class="line"></span><br><span class="line">        x = self.encode1(x)</span><br><span class="line">        x, id1 = F.max_pool2d_with_indices(x, kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, return_indices=<span class="literal">True</span>)</span><br><span class="line">        idx.append(id1)</span><br><span class="line"></span><br><span class="line">        x = self.encode2(x)</span><br><span class="line">        x, id2 = F.max_pool2d_with_indices(x, kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, return_indices=<span class="literal">True</span>)</span><br><span class="line">        idx.append(id2)</span><br><span class="line"></span><br><span class="line">        x = self.encode3(x)</span><br><span class="line">        x, id3 = F.max_pool2d_with_indices(x, kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, return_indices=<span class="literal">True</span>)</span><br><span class="line">        idx.append(id3)</span><br><span class="line"></span><br><span class="line">        x = self.encode4(x)</span><br><span class="line">        x, id4 = F.max_pool2d_with_indices(x, kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, return_indices=<span class="literal">True</span>)</span><br><span class="line">        idx.append(id4)</span><br><span class="line"></span><br><span class="line">        x = self.encode5(x)</span><br><span class="line">        x, id5 = F.max_pool2d_with_indices(x, kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, return_indices=<span class="literal">True</span>)</span><br><span class="line">        idx.append(id5)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x, idx</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Decoder</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, out_channels</span>):</span><br><span class="line">        <span class="built_in">super</span>(Decoder, self).__init__()</span><br><span class="line"></span><br><span class="line">        batchNorm_momentum = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line">        self.decode1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">512</span>, momentum=batchNorm_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">512</span>, momentum=batchNorm_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.decode2 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">512</span>, momentum=batchNorm_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">512</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">256</span>, momentum=batchNorm_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.decode3 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">256</span>, momentum=batchNorm_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">256</span>, <span class="number">128</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">128</span>, momentum=batchNorm_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.decode4 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">128</span>, <span class="number">128</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">128</span>, momentum=batchNorm_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">128</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">64</span>, momentum=batchNorm_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.decode5 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">64</span>, momentum=batchNorm_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">64</span>, out_channels, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, idx</span>):</span><br><span class="line">        x = F.max_unpool2d(x, idx[<span class="number">4</span>], kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        x = self.decode1(x)</span><br><span class="line">        x = F.max_unpool2d(x, idx[<span class="number">3</span>], kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        x = self.decode2(x)</span><br><span class="line">        x = F.max_unpool2d(x, idx[<span class="number">2</span>], kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        x = self.decode3(x)</span><br><span class="line">        x = F.max_unpool2d(x, idx[<span class="number">1</span>], kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        x = self.decode4(x)</span><br><span class="line">        x = F.max_unpool2d(x, idx[<span class="number">0</span>], kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        x = self.decode5(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SegNet</span>(nn.Module):</span><br><span class="line">    <span class="comment"># https://arxiv.org/abs/1511.00561</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(SegNet, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.encode = Encoder(in_channels=<span class="number">3</span>)</span><br><span class="line">        self.decode = Decoder(out_channels=num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x, idx = self.encode(x)</span><br><span class="line">        x = self.decode(x, idx)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="built_in">input</span> = torch.randn(<span class="number">1</span>, <span class="number">3</span>, <span class="number">384</span>, <span class="number">544</span>)</span><br><span class="line">    model = SegNet(num_classes=<span class="number">2</span>)</span><br><span class="line">    output = model(<span class="built_in">input</span>)</span><br><span class="line">    <span class="built_in">print</span>(output.shape)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>图像分割</category>
      </categories>
      <tags>
        <tag>模型</tag>
        <tag>图像分割</tag>
      </tags>
  </entry>
  <entry>
    <title>Optimizer</title>
    <url>/2022/08/30/Optimizer/</url>
    <content><![CDATA[<h1 id="各种优化器总结与比较"><a href="#各种优化器总结与比较" class="headerlink" title="各种优化器总结与比较"></a>各种优化器总结与比较</h1><p>优化器就是在深度学习反向传播过程中，指引损失函数（目标函数）的各个参数往正确的方向更新合适的大小，使得更新后的各个参数让损失函数（目标函数）值不断逼近全局最小。</p>
<span id="more"></span>
<h2 id="1-梯度下降法-Gradient-Descent"><a href="#1-梯度下降法-Gradient-Descent" class="headerlink" title="1. 梯度下降法(Gradient Descent)"></a>1. 梯度下降法(Gradient Descent)</h2><p>依据计算目标函数梯度使用的数据量的不同，有三种梯度下降的变体，即批量梯度下降，随机梯度下降，Mini-batch梯度下降。根据数据量的大小，在参数更新的准确性和执行更新所需时间之间做了一个权衡。</p>
<h3 id="1-1-批量梯度下降"><a href="#1-1-批量梯度下降" class="headerlink" title="1.1 批量梯度下降"></a>1.1 批量梯度下降</h3><p>标准的梯度下降，即批量梯度下降（batch gradient descent,BGD），在整个训练集上计算损失函数关于参数$\theta$的梯度。</p>
<script type="math/tex; mode=display">\theta=\theta-\eta \nabla_{\theta}J(\theta)</script><p>其中$\theta$是模型的参数，$\eta$是学习率，$\nabla_{\theta}J(\theta)$为损失函数对参数$\theta$的导数。由于为了一次参数更新我们需要在整个训练集上计算梯度，导致 BGD 可能会非常慢，而且在训练集太大而不能全部载入内存的时候会很棘手。BGD 也不允许我们在线更新模型参数，即实时增加新的训练样本。</p>
<p>BGD 对于凸误差曲面（convex error surface）保证收敛到全局最优点，而对于非凸曲面（non-convex surface）则是局部最优点。</p>
<h3 id="1-2-随机梯度下降"><a href="#1-2-随机梯度下降" class="headerlink" title="1.2 随机梯度下降"></a>1.2 随机梯度下降</h3><p>随机梯度下降（ stotastic gradient descent, SGD ）则是每次使用一个训练样本$x^{i}$和标签$y^{i}$进行一次参数更新。</p>
<script type="math/tex; mode=display">\theta=\theta -\eta \cdot \nabla_{\theta}J(\theta;x^i;y^i)</script><p>其中$\theta$是模型的参数，$\eta$是学习率，$\nabla_{\theta}J(\theta)$为损失函数对参数$\theta$的导数。BGD 对于大数据集来说执行了很多冗余的计算，因为在每一次参数更新前都要计算很多相似样本的梯度。SGD 通过一次执行一次更新解决了这种冗余。因此通常 SGD 的速度会非常快而且可以被用于在线学习。SGD以高方差的特点进行连续参数更新，导致目标函数严重震荡</p>
<p>BGD 能够收敛到（局部）最优点，然而 SGD 的震荡特点导致其可以跳到新的潜在的可能更好的局部最优点。已经有研究显示当我们慢慢的降低学习率时，SGD 拥有和 BGD 一样的收敛性能，对于非凸和凸曲面几乎同样能够达到局部或者全局最优点。</p>
<h3 id="1-3-Mini-batch梯度下降"><a href="#1-3-Mini-batch梯度下降" class="headerlink" title="1.3 Mini-batch梯度下降"></a>1.3 Mini-batch梯度下降</h3><p>Mini-batch gradient descent（ mini-batch gradient descent, MBGD ）则是在上面两种方法中采取了一个折中的办法：每次从训练集中取出$batch  size$个样本作为一个mini-batch，以此来进行一次参数更新。</p>
<script type="math/tex; mode=display">\theta=\theta -\eta \cdot \nabla_{\theta} J(\theta;x^{(i:i+n);y^{(i:i+n)}})</script><p>其中$\theta$是模型的参数，$\eta$是学习率，$\nabla_{\theta} J(\theta;x^{(i:i+n);y^{(i:i+n)}}$为损失函数对参数$\theta$的导数，n为Mini-bach的大小（batch size）。 batch size越大，批次越少，训练时间会更快一点，但可能造成数据的很大浪费；而batch size越小，对数据的利用越充分，浪费的数据量越少，但批次会很大，训练会更耗时。</p>
<p><strong>优点</strong></p>
<ul>
<li>减小参数更新的方差，这样可以有更稳定的收敛。</li>
<li>利用现在最先进的深度学习库对矩阵运算进行了高度优化的特点，这样可以使得计算 mini-batch 的梯度更高效。</li>
</ul>
<p>MBGD 是训练神经网络时的常用方法，而且通常即使实际上使用的是 MBGD，也会使用 SGD 这个词来代替。</p>
<h3 id="1-4-学习率的选择"><a href="#1-4-学习率的选择" class="headerlink" title="1.4 学习率的选择"></a>1.4 学习率的选择</h3><p>选择一个好的学习率是非常困难的。太小的学习率导致收敛非常缓慢，而太大的学习率则会阻碍收敛，导致损失函数在最优点附近震荡甚至发散。相同的学习率被应用到所有参数更新中。</p>
<h2 id="2-动量优化法"><a href="#2-动量优化法" class="headerlink" title="2. 动量优化法"></a>2. 动量优化法</h2><p>动量优化方法是在梯度下降法的基础上进行的改变，具有加速梯度下降的作用。一般有标准动量优化方法Momentum、NAG（Nesterov accelerated gradient）动量优化方法。</p>
<h3 id="2-1-Momentum"><a href="#2-1-Momentum" class="headerlink" title="2.1 Momentum"></a>2.1 Momentum</h3><p>为了抑制SGD的震荡，SGDM认为梯度下降过程可以加入惯性。可以简单理解为：当我们将一个小球从山上滚下来时，没有阻力的话，它的动量会越来越大，但是如果遇到了阻力，速度就会变小。SGDM全称是SGD with momentum，在SGD基础上引入了一阶动量：</p>
<script type="math/tex; mode=display">v_{t}=\gamma v_{t-1}+\eta \nabla J(\theta)</script><p>SGD-M参数更新公式如下，其中$\eta$是学习率，$\nabla J(\theta)$是当前参数的梯度</p>
<script type="math/tex; mode=display">\theta=\theta-v_{t}</script><p>一阶动量是各个时刻梯度方向的指数移动平均值，也就是说，t时刻的下降方向，不仅由当前点的梯度方向决定，而且由此前累积的下降方向决定。$\gamma$的经验值为0.9，这就意味着下降方向主要是此前累积的下降方向，并略微偏向当前时刻的下降方向。</p>
<p><strong>特点</strong></p>
<ul>
<li>加入了动量因素，SGD-M缓解了SGD在局部最优点梯度为0，无法持续更新的问题和振荡幅度过大的问题。</li>
<li>当局部沟壑比较深，动量加持用完了，依然会困在局部最优里来回振荡</li>
</ul>
<h3 id="2-2-NAG"><a href="#2-2-NAG" class="headerlink" title="2.2 NAG"></a>2.2 NAG</h3><p>NAG全称Nesterov Accelerated Gradient，是在SGD、SGD-M的基础上的进一步改进，我们知道在时刻$t$的主要下降方向是由累积动量决定的，自己的梯度方向说了也不算，那与其看当前梯度方向，不如先看看如果跟着累积动量走了一步，那个时候再怎么走。因此，NAG不计算当前位置的梯度方向，而是计算如果按照累积动量走了一步，那个时候的下降方向：</p>
<script type="math/tex; mode=display">v_{t}=\gamma v_{t-1}+\eta \nabla_{\theta}J(\theta-\gamma v_{t-1})</script><p>NAG参数更新公式如下，其中$\eta$是学习率， $\nabla_{\theta}J(\theta-\gamma v_{t-1})$是当前参数的梯度</p>
<script type="math/tex; mode=display">\theta=\theta-v_{t}</script><p>然后用下一个点的梯度方向，与历史累积动量相结合，计算当前时刻的累积动量。</p>
<p><strong>特点</strong></p>
<ul>
<li>有利于跳出当前局部最优的沟壑，寻找新的最优值，但收敛速度慢</li>
</ul>
<h2 id="3-自适应学习率优化算法"><a href="#3-自适应学习率优化算法" class="headerlink" title="3. 自适应学习率优化算法"></a>3. 自适应学习率优化算法</h2><p>自适应学习率优化算法针对于机器学习模型的学习率，传统的优化算法要么将学习率设置为常数要么根据训练次数调节学习率。极大忽视了学习率其他变化的可能性。然而，学习率对模型的性能有着显著的影响，因此需要采取一些策略来想办法更新学习率，从而提高训练速度。<br>目前的自适应学习率优化算法主要有：AdaGrad算法，AdaDelta算法, RMSProp算法以及Adam算法。</p>
<h3 id="3-1-AdaGrad"><a href="#3-1-AdaGrad" class="headerlink" title="3.1 AdaGrad"></a>3.1 AdaGrad</h3><p>AdaGrad算法就是将每一个参数的每一次迭代的梯度取平方累加后在开方，用全局学习率除以这个数，作为学习率的动态更新。对于不同的参数动态的采取不同的学习率，让目标函数更快的收敛。为了简洁，我们用$g_{t}$来表示t时刻的梯度，$g_{t,i}$就是目标函数的偏导数：</p>
<script type="math/tex; mode=display">g_{t,i}=\nabla_{\theta}J(\theta_{t,i})</script><p>SGD在在每个时刻t对参数$\theta_{i}$的更新为：</p>
<script type="math/tex; mode=display">\theta_{t+1,i}=\theta_{t,i}-\eta \cdot g_{t,i}</script><p>Adagrad修改了t时刻对于每个参数$\theta_{i}$的学习率$\eta$:</p>
<script type="math/tex; mode=display">\theta_{t+1,i}=\theta_{t,i}-\frac{\eta}{\sqrt{G_{t,ii}+\epsilon}} \cdot g_{t,i}</script><p>其中$G_{t}\in R^{d \times d}$是对角矩阵，其中每一个对角元素i，i是$\theta_{i}$在时刻t的梯度平方和，一般为了避免分母为0，会在分母上加一个小的平滑项，用符号$\epsilon$表示，通常为$10^{-8}$ 左右。因此$\sqrt{G_{t}+\epsilon} $恒大于0，而且参数更新越频繁，二阶动量越大，学习率就越小。有趣的是，如果去掉开方操作，算法性能会大幅下降。</p>
<p><strong>优点</strong></p>
<ul>
<li>在稀疏数据场景下表现非常好</li>
<li>此前的SGD及其变体的优化器主要聚焦在优化梯度前进的方向上，而AdaGrad首次使用二阶动量来关注学习率（步长），开启了自适应学习率算法的里程。大多数实现使用一个默认值 0.01 。</li>
</ul>
<p><strong>缺点</strong></p>
<ul>
<li>$\sqrt{G_{t}+\epsilon}$是单调递增的，会使得学习率单调递减至0，可能会使得训练过程提前结束，即便后续还有数据也无法学到必要的知识。</li>
</ul>
<h3 id="3-2-AdaDelta"><a href="#3-2-AdaDelta" class="headerlink" title="3.2 AdaDelta"></a>3.2 AdaDelta</h3><p>由于AdaGrad单调递减的学习率变化过于激进，考虑一个改变二阶动量计算方法的策略：不累积全部历史梯度，而只关注过去一段时间窗口的下降梯度。这也就是AdaDelta名称中Delta的来历。Adadelta是 Adagrad 的扩展，旨在帮助缓解后者学习率单调下降的问题。</p>
<p>指数移动平均值大约就是过去一段时间的平均值，因此我们用这一方法来计算二阶累积动量：</p>
<script type="math/tex; mode=display">E[g^2]_{t}=\gamma E[g^2]_{t-1}+(1-\gamma) g_{t}^2</script><p>其中$\gamma$类似于冲量，大约是0.9.现在将SGD更新的参数变化向量$\Delta \theta_{t}$:</p>
<script type="math/tex; mode=display">\Delta \theta_{t}=-\eta \cdot g_{t,i}</script><script type="math/tex; mode=display">\theta_{t+1}=\theta_{t}+\Delta \theta_{t}</script><p>在Adagrad中，$\Delta \theta_{t}$是由：</p>
<script type="math/tex; mode=display">\Delta \theta_{t}=-\frac{\eta}{\sqrt{G_{t}+\epsilon}}\cdot g_{t,i}</script><p>表示的，现在用$E[g^2]_{t}$简单代替原来的对角矩阵$G_{t}$：</p>
<script type="math/tex; mode=display">\Delta \theta_{t}=-\frac{\eta}{\sqrt{E[g^2]_{t}+\epsilon}}\cdot g_{t,i}</script><p>将分母简记为RMS，表示梯度的均方根误差：</p>
<script type="math/tex; mode=display">\Delta \theta_{t}=-\frac{\eta}{RMS[g]_{t}}\cdot g_{t}</script><p>根据作者所说，更新中，定义指数衰减均值，代替梯度平方：</p>
<script type="math/tex; mode=display">E[\Delta \theta^2]_{t}=\gamma E[\Delta \theta^2]_{t-1}+(1-\gamma)\Delta \theta_{t}^2</script><p>均方根误差变为：</p>
<script type="math/tex; mode=display">RMS[\Delta \theta]_{t}=\sqrt{E[\Delta \theta^2]_{t}+\epsilon}</script><p>$RMS[\Delta \theta]_{t}$是未知的，我们近似用前一个时间步RMS值来估计：</p>
<script type="math/tex; mode=display">\Delta \theta_{t}=-\frac{RMS[\Delta \theta]_{t-1}}{RMS[g]_{t}}g_{t}</script><script type="math/tex; mode=display">\theta_{t+1}=\theta_{t}-\Delta \theta_{t}</script><p>Adadelta不用设置学习率，因为其更新规则已经把它消除了。</p>
<p><strong>优点</strong></p>
<ul>
<li>避免了二阶动量持续累积、导致训练过程提前结束的问题了</li>
</ul>
<h3 id="3-3-RMSProp"><a href="#3-3-RMSProp" class="headerlink" title="3.3 RMSProp"></a>3.3 RMSProp</h3><p>RMSProp 算法（Hinton，2012）修改 AdaGrad 以在非凸情况下表现更好，它改变梯度累积为指数加权的移动平均值，从而丢弃距离较远的历史梯度信息。RMSProp 与 Adadelta 的移动均值更新方式十分相似：</p>
<script type="math/tex; mode=display">E[g^2]_{t}=0.9 E[g^2]_{t-1}+0.1 g_{t}^2</script><p>RMSProp参数更新公式如下，其中$\eta$是学习率， $g_{t}$是当前参数的梯度</p>
<script type="math/tex; mode=display">\theta_{t+1}=\theta_{t}-\frac{\eta}{\sqrt{E[g^2]_{t}+\epsilon}}g_{t}</script><p>RMSprop将学习速率除以梯度平方的指数衰减平均值。Hinton建议$\gamma$设置为0.9，默认学习率$\eta$为0.001</p>
<h3 id="3-4-Adam"><a href="#3-4-Adam" class="headerlink" title="3.4 Adam"></a>3.4 Adam</h3><p>Adam最开始是由 OpenAI 的 Diederik Kingma 和多伦多大学的 Jimmy Ba提出的。Adam使用动量和自适应学习率来加快收敛速度。SGD-M在SGD基础上增加了一阶动量，AdaGrad和AdaDelta在SGD基础上增加了二阶动量（二阶矩估计）。把一阶动量和二阶动量都用起来，就是Adam了——Adaptive + Momentum。</p>
<p>SGD的一阶矩的估计，即mean均值：</p>
<script type="math/tex; mode=display">m_{t}=\beta_{1} \cdot m_{t-1}+(1-\beta_{1}) \cdot g_{t}</script><p>加上AdaDelta的二阶动量，二阶距的估计，即variance，和方差类似，都是二阶距的一种：</p>
<script type="math/tex; mode=display">v_{t}=\beta_{2} \cdot v_{t-1}+(1-\beta_{2})\cdot g_{t}^2</script><p>对mean和var进行校正，因为mean和var的初始值为0，所以它们会向0偏置，这样处理后会减少这种偏置影响。</p>
<script type="math/tex; mode=display">\hat m_{t}=\frac{m_{t}}{1-\beta_{1}^t}</script><script type="math/tex; mode=display">\hat v_{t}=\frac{v_{t}}{1-\beta_{2}^t}</script><p>Adam参数更新公式如下：</p>
<script type="math/tex; mode=display">\theta_{t+1}=\theta_{t}-\eta \cdot \hat m_{t}/(\sqrt{\hat v_{t}}+\epsilon)</script><p>其中$\eta$是学习率， $g_{t}$是当前参数的梯度，$\beta_{1}$为一阶矩估计的指数衰减率（如 0.9），$\beta_{2}$二阶矩估计的指数衰减率（如 0.999），前者控制一阶矩估计，后者控制二阶矩估计。该超参数在稀疏梯度（如在 NLP 或计算机视觉任务中）中应该设置为接近 1 的数，$\beta_{1}^t$和$\beta_{2}^t$是$\beta_{1}$和$\beta_{2}$的t次方</p>
<p><strong>优点</strong></p>
<ul>
<li>通过一阶动量和二阶动量，有效控制学习率步长和梯度方向，防止梯度的振荡和在鞍点的静止。</li>
<li>实现简单，计算高效，对内存需求少</li>
<li>参数的更新不受梯度的伸缩变换影响</li>
<li>超参数具有很好的解释性，且通常无需调整或仅需很少的微调</li>
<li>更新的步长能够被限制在大致的范围内（初始学习率）</li>
<li>能自然地实现步长退火过程（自动调整学习率）</li>
<li>很适合应用于大规模的数据及参数的场景</li>
<li>适用于不稳定目标函数</li>
<li>适用于梯度稀疏或梯度存在很大噪声的问题</li>
</ul>
<p>Adam在很多情况下算作默认工作性能比较优秀的优化器。</p>
<p><strong>缺点</strong></p>
<ul>
<li><p>可能不收敛：二阶动量是固定时间窗口内的累积，随着时间窗口的变化，遇到的数据可能发生巨变，使得$V_{t}$可能会时大时小，不是单调变化。这就可能在训练后期引起学习率的震荡，导致模型无法收敛。</p>
<p>  修正的方法。由于Adam中的学习率主要是由二阶动量控制的，为了保证算法的收敛，可以对二阶动量的变化进行控制，避免上下波动。</p>
<script type="math/tex; mode=display">v_{t}=max(\beta_{2} \cdot v_{t-1}+ (1-\beta_{2})g_{t}^2,v_{t-1})</script></li>
<li><p>可能错过全局最优解：自适应学习率算法可能会对前期出现的特征过拟合，后期才出现的特征很难纠正前期的拟合效果。后期Adam的学习率太低，影响了有效的收敛。</p>
</li>
</ul>
<h2 id="4-可视化比较"><a href="#4-可视化比较" class="headerlink" title="4. 可视化比较"></a>4. 可视化比较</h2><p><img src="https://img-blog.csdn.net/20180426130002689" alt=""></p>
]]></content>
      <categories>
        <category>深度学习基础</category>
      </categories>
      <tags>
        <tag>数学</tag>
        <tag>优化器</tag>
      </tags>
  </entry>
  <entry>
    <title>U-Net</title>
    <url>/2021/12/27/U-Net/</url>
    <content><![CDATA[<h1 id="U-Net论文详解"><a href="#U-Net论文详解" class="headerlink" title="U-Net论文详解"></a>U-Net论文详解</h1><blockquote>
<p>U-Net结构由一个用于捕获上下文信息的压缩路径和一个支持精确定位的对称扩展路径构成。实验结果表明可以从很少的图像进行端到端的训练，并在ISBI挑战上优于先前最优的方法(滑动窗口卷积网络)，并获得了冠军</p>
</blockquote>
<span id="more"></span>
<h2 id="1-背景介绍"><a href="#1-背景介绍" class="headerlink" title="1. 背景介绍"></a>1. 背景介绍</h2><p>卷积网络的典型应用是分类任务，其中图像的输出是一个单一的类标签。然而在许多视觉任务中，特别是生物医学图像处理中，期望的输出应该包含定位，即给每一个像素点分配一个类标签。</p>
<p>于是滑动窗口卷积网络通过提供像素点周围的局部区域来预测每个像素的类别标签。但是这样的方法存在两个缺点：</p>
<ol>
<li>速度特别慢，网络必须为每一个窗口单元单独运行，并且窗口单元重合而导致大量冗余</li>
<li>在定位精度和上下文信息之间的权衡。大的窗口单元需要更多的max pooling层，这会降低精度；而小的窗口单元捕获的上下文信息较少。</li>
</ol>
<p>于是本文提出了U-Net网络</p>
<h2 id="2-U-Net网络架构"><a href="#2-U-Net网络架构" class="headerlink" title="2. U-Net网络架构"></a>2. U-Net网络架构</h2><p><img src="https://img-blog.csdnimg.cn/ee65efa0cb8e4ceabf581b6ab7a9281e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5L2V5aaC5Y2D5rO3,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<p><strong>网络是一个经典的全卷积网络。网络的输入是一张572x572经过镜像操作的图像。为了使得每次下采样后特征图的尺寸为偶数。</strong><br><img src="https://img-blog.csdnimg.cn/ab4fe06a1a854b6ebd19b575a37c0c3e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5L2V5aaC5Y2D5rO3,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<p>网络的左侧为<strong>压缩路径</strong>，由<strong>4个block</strong>构成，<strong>每个block由2个未padding的卷积和一个最大池化构成，其中每次卷积特征图的尺寸为减小2，最大池化后会缩小一半。</strong></p>
<p><strong>现在大部分采用same padding的卷积，这样就不用对输入进行镜像操作，而且在拼接压缩路径与对应的扩展路径也不用进行裁剪，而且裁剪会使得特征图不对称</strong></p>
<p>网络的右侧为<strong>扩展路径</strong>，同样由<strong>4个bloc</strong>k构成，每个block开始之前通过<strong>反卷积将特征图的尺寸扩大一倍</strong>，然后与压缩路径对应的特征图拼接，<strong>由于采用未padding的卷积，左侧压缩路径的特征图的尺寸比右侧扩展路径的特征图的大，所以需要先进行裁剪，使其大小相同，然后拼接</strong>，然后<strong>经过两次未padding的卷积</strong>进一步提取特征</p>
<p>最后根据自己的任务，输出对应大小的预测特征图</p>
<p>现在大部分采用<strong>双线性插值代替反卷积</strong>，而且效果会更好</p>
<h2 id="3-数据增强"><a href="#3-数据增强" class="headerlink" title="3. 数据增强"></a>3. 数据增强</h2><p>我们主要通过平移和旋转不变性以及灰度值的变化来增强模型的鲁棒性，特别地，<strong>任意的弹性形变对训练非常有帮助</strong>。</p>
<h2 id="4-Pytorch实现"><a href="#4-Pytorch实现" class="headerlink" title="4. Pytorch实现"></a>4. Pytorch实现</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Encoder</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels</span>):</span><br><span class="line">        <span class="built_in">super</span>(Encoder, self).__init__()</span><br><span class="line">        self.block1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">        self.block2 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(out_channels, out_channels, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">        self.pool = nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.block1(x)</span><br><span class="line">        x = self.block2(x)</span><br><span class="line">        x_pooled = self.pool(x)</span><br><span class="line">        <span class="keyword">return</span> x, x_pooled</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Decoder</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels</span>):</span><br><span class="line">        <span class="built_in">super</span>(Decoder, self).__init__()</span><br><span class="line">        self.up_sample = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line">        self.block1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">        self.block2 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(out_channels, out_channels, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x_prev, x</span>):</span><br><span class="line">        x = self.up_sample(x)</span><br><span class="line">        x_shape = x.shape[<span class="number">2</span>:]</span><br><span class="line">        x_prev_shape = x.shape[<span class="number">2</span>:]</span><br><span class="line">        h_diff = x_prev_shape[<span class="number">0</span>] - x_shape[<span class="number">0</span>]</span><br><span class="line">        w_diff = x_prev_shape[<span class="number">1</span>] - x_shape[<span class="number">1</span>]</span><br><span class="line">        <span class="comment"># padding</span></span><br><span class="line">        x_tmp = torch.zeros(x_prev.shape).to(x.device)</span><br><span class="line">        x_tmp[:, :, h_diff//<span class="number">2</span>: h_diff+x_shape[<span class="number">0</span>], w_diff//<span class="number">2</span>: x_shape[<span class="number">1</span>]] = x</span><br><span class="line">        x = torch.cat([x_prev, x_tmp], dim=<span class="number">1</span>)</span><br><span class="line">        x = self.block1(x)</span><br><span class="line">        x = self.block2(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">UNet</span>(nn.Module):</span><br><span class="line">    <span class="comment"># https://arxiv.org/abs/1505.04597</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes=<span class="number">2</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(UNet, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.down_sample1 = Encoder(in_channels=<span class="number">3</span>, out_channels=<span class="number">64</span>)</span><br><span class="line">        self.down_sample2 = Encoder(in_channels=<span class="number">64</span>, out_channels=<span class="number">128</span>)</span><br><span class="line">        self.down_sample3 = Encoder(in_channels=<span class="number">128</span>, out_channels=<span class="number">256</span>)</span><br><span class="line">        self.down_sample4 = Encoder(in_channels=<span class="number">256</span>, out_channels=<span class="number">512</span>)</span><br><span class="line"></span><br><span class="line">        self.mid1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">512</span>, <span class="number">1024</span>, <span class="number">3</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">        self.mid2 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">1024</span>, <span class="number">1024</span>, <span class="number">3</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.up_sample1 = Decoder(in_channels=<span class="number">1024</span>, out_channels=<span class="number">512</span>)</span><br><span class="line">        self.up_sample2 = Decoder(in_channels=<span class="number">512</span>, out_channels=<span class="number">256</span>)</span><br><span class="line">        self.up_sample3 = Decoder(in_channels=<span class="number">256</span>, out_channels=<span class="number">128</span>)</span><br><span class="line">        self.up_sample4 = Decoder(in_channels=<span class="number">128</span>, out_channels=<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line">        self.classifier = nn.Conv2d(<span class="number">64</span>, num_classes, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x1, x = self.down_sample1(x)</span><br><span class="line">        x2, x = self.down_sample2(x)</span><br><span class="line">        x3, x = self.down_sample3(x)</span><br><span class="line">        x4, x = self.down_sample4(x)</span><br><span class="line"></span><br><span class="line">        x = self.mid1(x)</span><br><span class="line">        x = self.mid2(x)</span><br><span class="line"></span><br><span class="line">        x = self.up_sample1(x4, x)</span><br><span class="line">        x = self.up_sample2(x3, x)</span><br><span class="line">        x = self.up_sample3(x2, x)</span><br><span class="line">        x = self.up_sample4(x1, x)</span><br><span class="line"></span><br><span class="line">        x = self.classifier(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="built_in">input</span> = torch.rand(<span class="number">1</span>, <span class="number">3</span>, <span class="number">384</span>, <span class="number">384</span>)</span><br><span class="line">    model = UNet(<span class="number">2</span>)</span><br><span class="line">    out = model(<span class="built_in">input</span>)</span><br><span class="line">    <span class="built_in">print</span>(out.shape)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>图像分割</category>
      </categories>
      <tags>
        <tag>模型</tag>
        <tag>图像分割</tag>
      </tags>
  </entry>
  <entry>
    <title>图像分割损失函数汇总</title>
    <url>/2022/08/29/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E6%B1%87%E6%80%BB/</url>
    <content><![CDATA[<h1 id="图像分割损失函数汇总"><a href="#图像分割损失函数汇总" class="headerlink" title="图像分割损失函数汇总"></a>图像分割损失函数汇总</h1><p>在本文中，总结了大多数广泛应用于图像分割的损失函数，并通过<code>Pytorch</code>框架进行了实现。<br><span id="more"></span></p>
<h2 id="1-BCELoss："><a href="#1-BCELoss：" class="headerlink" title="1. BCELoss："></a>1. BCELoss：</h2><script type="math/tex; mode=display">l(x,y)=L=\{l_1,...,l_N\}^T</script><script type="math/tex; mode=display">l_n=-w_n[y_n \cdot logx_n + (1-y_n) \cdot log(1-x_n)]</script><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BCELoss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 weight=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 pos_weight=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 ignore_index=<span class="number">255</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :param weight: A manual rescaling weight given to the loss of each batch element</span></span><br><span class="line"><span class="string">        :param pos_weight: A weight of positive examples</span></span><br><span class="line"><span class="string">        :param ignore_index: Specifies a target value that is ignored and does not contribute to the input gradient</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(BCELoss, self).__init__()</span><br><span class="line">        self.weight = weight</span><br><span class="line">        self.pos_weight = pos_weight</span><br><span class="line">        self.ignore_index = ignore_index</span><br><span class="line">        self.EPS = <span class="number">1e-10</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, logit, label</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :param logit: Logit tensor, the data type is float32, float64. Shape is</span></span><br><span class="line"><span class="string">                (N, C), where C is number of classes, and if shape is more than 2D, this</span></span><br><span class="line"><span class="string">                is (N, C, D1, D2,..., Dk), k &gt;= 1.</span></span><br><span class="line"><span class="string">        :param label: Label tensor, the data type is int64. Shape is (N, C), where each</span></span><br><span class="line"><span class="string">                value is 0 or 1, and if shape is more than 2D, this is</span></span><br><span class="line"><span class="string">                (N, C, D1, D2,..., Dk), k &gt;= 1.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(label.shape) != <span class="built_in">len</span>(logit.shape):</span><br><span class="line">            label = torch.unsqueeze(label, dim=<span class="number">1</span>)</span><br><span class="line">        mask = (label != self.ignore_index)</span><br><span class="line">        mask = mask.to(dtype=torch.float32)</span><br><span class="line">        <span class="keyword">if</span> label.shape[<span class="number">1</span>] != logit.shape[<span class="number">1</span>]:</span><br><span class="line">            label = label.squeeze(<span class="number">1</span>)</span><br><span class="line">            label = F.one_hot(label, logit.shape[<span class="number">1</span>])</span><br><span class="line">            label = torch.permute(label, dims=(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line">        label = label.to(dtype=torch.float32)</span><br><span class="line">        loss = F.binary_cross_entropy_with_logits(</span><br><span class="line">            <span class="built_in">input</span>=logit,</span><br><span class="line">            target=label,</span><br><span class="line">            weight=self.weight,</span><br><span class="line">            pos_weight=self.pos_weight,</span><br><span class="line">            reduction=<span class="string">&#x27;none&#x27;</span></span><br><span class="line">        )</span><br><span class="line">        loss = loss * mask</span><br><span class="line">        loss = torch.mean(loss) / (torch.mean(mask) + self.EPS)</span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    inp = torch.randn(<span class="number">4</span>, <span class="number">21</span>, <span class="number">448</span>, <span class="number">448</span>)</span><br><span class="line">    tgt = torch.randint(low=<span class="number">0</span>, high=<span class="number">20</span>, size=(<span class="number">4</span>, <span class="number">448</span>, <span class="number">448</span>))</span><br><span class="line">    loss = BCELoss()</span><br><span class="line">    <span class="built_in">print</span>(loss(inp, tgt))</span><br></pre></td></tr></table></figure>
<h2 id="2-CrossEntropyLoss"><a href="#2-CrossEntropyLoss" class="headerlink" title="2.CrossEntropyLoss:"></a>2.CrossEntropyLoss:</h2><script type="math/tex; mode=display">l(x, y)= L = \{l_1, ..., l_N\}^T</script><script type="math/tex; mode=display">l_n=-w_{y_n}log \frac {exp(x_{n, y_n})} {\sum_{c=1}^C exp(x_{n,c})} \cdot 1\{y_n \not = ignore\_index\}</script><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CELoss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 weight=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 ignore_index=<span class="number">255</span>,</span></span><br><span class="line"><span class="params">                 top_k_percent_pixels=<span class="number">1.0</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :param weight: (tuple|list|ndarray|Tensor, optional): A manual rescaling weight</span></span><br><span class="line"><span class="string">            given to each class. Its length must be equal to the number of classes.</span></span><br><span class="line"><span class="string">        :param ignore_index: (int64, optional): Specifies a target value that is ignored</span></span><br><span class="line"><span class="string">            and does not contribute to the input gradient. Default ``255``.</span></span><br><span class="line"><span class="string">        :param top_k_percent_pixels: (float, optional): the value lies in [0.0, 1.0].</span></span><br><span class="line"><span class="string">            When its value &lt; 1.0, only compute the loss for the top k percent pixels</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(CELoss, self).__init__()</span><br><span class="line">        self.weight = weight</span><br><span class="line">        self.ignore_index = ignore_index</span><br><span class="line">        self.top_k_percent_pixels = top_k_percent_pixels</span><br><span class="line">        self.EPS = <span class="number">1e-8</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, logit, label, semantic_weights=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :param logit: Logit tensor, the data type is float32, float64. Shape is</span></span><br><span class="line"><span class="string">                (N, C), where C is number of classes, and if shape is more than 2D, this</span></span><br><span class="line"><span class="string">                is (N, C, D1, D2,..., Dk), k &gt;= 1.</span></span><br><span class="line"><span class="string">        :param label: Label tensor, the data type is int64. Shape is (N), where each</span></span><br><span class="line"><span class="string">                value is 0 &lt;= label[i] &lt;= C-1, and if shape is more than 2D, this is</span></span><br><span class="line"><span class="string">                (N, D1, D2,..., Dk), k &gt;= 1.</span></span><br><span class="line"><span class="string">        :param semantic_weights: Weights about loss for each pixels,</span></span><br><span class="line"><span class="string">                shape is the same as label. Default: None.</span></span><br><span class="line"><span class="string">        :return: (Tensor): The average loss.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> self.weight <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            self.weight = torch.tensor(self.weight, dtype=torch.float32, device=logit.device)</span><br><span class="line">            <span class="keyword">if</span> logit.shape[<span class="number">1</span>] != <span class="built_in">len</span>(self.weight):</span><br><span class="line">                <span class="keyword">raise</span> ValueError(<span class="string">&quot;The number of weights = &#123;&#125; must be the same as the number of classes = &#123;&#125;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(self.weight), logit.shape[<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line">        label = label.to(dtype=torch.int64)</span><br><span class="line">        loss = F.cross_entropy(</span><br><span class="line">            <span class="built_in">input</span>=logit,</span><br><span class="line">            target=label,</span><br><span class="line">            ignore_index=self.ignore_index,</span><br><span class="line">            reduction=<span class="string">&#x27;none&#x27;</span>,</span><br><span class="line">            weight=self.weight</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">return</span> self._post_process_loss(logit, label, semantic_weights, loss)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_post_process_loss</span>(<span class="params">self, logit, label, semantic_weights, loss</span>):</span><br><span class="line">        mask = label != self.ignore_index</span><br><span class="line">        mask = mask.to(dtype=torch.float32)</span><br><span class="line">        <span class="keyword">if</span> loss.ndim &gt; mask.ndim:</span><br><span class="line">            loss = torch.squeeze(loss, dim=-<span class="number">1</span>)</span><br><span class="line">        loss = loss * mask</span><br><span class="line">        <span class="keyword">if</span> semantic_weights <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            loss = loss * semantic_weights</span><br><span class="line">        <span class="keyword">if</span> self.weight <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            _one_hot = F.one_hot(label * mask, logit.shape[<span class="number">1</span>])</span><br><span class="line">            coef = torch.<span class="built_in">sum</span>(_one_hot * self.weight, dim=-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            coef = torch.ones_like(label)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.top_k_percent_pixels == <span class="number">1.0</span>:</span><br><span class="line">            avg_loss = torch.mean(loss) / (torch.mean(mask * coef) + self.EPS)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            loss = loss.reshape((-<span class="number">1</span>, ))</span><br><span class="line">            top_k_pixels = <span class="built_in">int</span>(self.top_k_percent_pixels * loss.numel())</span><br><span class="line">            loss, indices = torch.topk(loss, top_k_pixels)</span><br><span class="line">            coef = coef.reshape((-<span class="number">1</span>, ))</span><br><span class="line">            coef = torch.gather(coef, dim=<span class="number">0</span>, index=indices)</span><br><span class="line">            coef = coef.to(dtype=torch.float32)</span><br><span class="line">            coef.requires_grad = <span class="literal">True</span></span><br><span class="line">            avg_loss = loss.mean() / (torch.mean(coef) + self.EPS)</span><br><span class="line">        <span class="keyword">return</span> avg_loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    inp = torch.randn(<span class="number">4</span>, <span class="number">21</span>, <span class="number">448</span>, <span class="number">448</span>)</span><br><span class="line">    tgt = torch.randint(low=<span class="number">0</span>, high=<span class="number">20</span>, size=(<span class="number">4</span>, <span class="number">448</span>, <span class="number">448</span>))</span><br><span class="line">    loss = CELoss(top_k_percent_pixels=<span class="number">0.8</span>)</span><br><span class="line">    <span class="built_in">print</span>(loss(inp, tgt))</span><br></pre></td></tr></table></figure>
<h2 id="3-Focal-Loss"><a href="#3-Focal-Loss" class="headerlink" title="3. Focal Loss:"></a>3. Focal Loss:</h2><p><img src="https://production-media.paperswithcode.com/methods/Screen_Shot_2020-06-07_at_4.45.06_PM_leJm2yh.png" alt=""></p>
<script type="math/tex; mode=display">CE(p_t) = -log(p_t)</script><script type="math/tex; mode=display">FL(p_t)=-\alpha(1-p_t)^\gamma log(p_t)</script><p>其中：$p_t=\frac {exp(x_{n, t})} {\sum_{c=1}^C exp(x_{n,c})}$表示样本属于<code>true class</code>的概率，$\alpha , \gamma$是超参数。</p>
<p>通过添加$(1-p_t)^\gamma$的目的是：<strong>减少易分类样本的权重，从而使得模型在训练时更专注于难分类的样本。</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FocalLoss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, alpha=<span class="number">1.0</span>, gamma=<span class="number">2.0</span>, ignore_index=<span class="number">255</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :param alpha: The alpha of Focal Loss</span></span><br><span class="line"><span class="string">        :param gamma: The gamma of Focal Loss</span></span><br><span class="line"><span class="string">        :param ignore_index: Specifies a target value that is ignored and does not contribute to the input gradient</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(FocalLoss, self).__init__()</span><br><span class="line">        self.alpha = alpha</span><br><span class="line">        self.gamma = gamma</span><br><span class="line">        self.ignore_index = ignore_index</span><br><span class="line">        self.EPS = <span class="number">1e-10</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, logit, label</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :param logit: Logit tensor, the data type is float32, float64. Shape is</span></span><br><span class="line"><span class="string">                (N, C, H, W), where C is number of classes.</span></span><br><span class="line"><span class="string">        :param label: Label tensor, the data type is int64. Shape is (N, H, W),</span></span><br><span class="line"><span class="string">                where each value is 0 &lt;= label[i] &lt;= C-1.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">assert</span> logit.ndim == <span class="number">4</span>, <span class="string">&quot;The ndim of logit should be 4&quot;</span></span><br><span class="line">        <span class="keyword">assert</span> label.ndim == <span class="number">3</span>, <span class="string">&quot;The ndim of label should be 3&quot;</span></span><br><span class="line">        label = label.to(dtype=torch.int64)</span><br><span class="line">        ce_loss = F.cross_entropy(</span><br><span class="line">            <span class="built_in">input</span>=logit,</span><br><span class="line">            target=label,</span><br><span class="line">            ignore_index=self.ignore_index,</span><br><span class="line">            reduction=<span class="string">&#x27;none&#x27;</span></span><br><span class="line">        )</span><br><span class="line">        pt = torch.exp(-ce_loss)</span><br><span class="line">        focal_loss = self.alpha * ((<span class="number">1</span> - pt) ** self.gamma) * ce_loss</span><br><span class="line">        mask = label != self.ignore_index</span><br><span class="line">        mask = mask.to(dtype=torch.float32)</span><br><span class="line">        focal_loss *= mask</span><br><span class="line">        avg_loss = torch.mean(focal_loss) / (torch.mean(mask) + self.EPS)</span><br><span class="line">        <span class="keyword">return</span> avg_loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    inp = torch.randn(<span class="number">4</span>, <span class="number">21</span>, <span class="number">448</span>, <span class="number">448</span>)</span><br><span class="line">    tgt = torch.randint(low=<span class="number">0</span>, high=<span class="number">20</span>, size=(<span class="number">4</span>, <span class="number">448</span>, <span class="number">448</span>))</span><br><span class="line">    loss = FocalLoss()</span><br><span class="line">    <span class="built_in">print</span>(loss(inp, tgt))</span><br></pre></td></tr></table></figure>
<h2 id="4-Dice-Loss"><a href="#4-Dice-Loss" class="headerlink" title="4. Dice Loss"></a>4. Dice Loss</h2><script type="math/tex; mode=display">L_{dice}=1-\frac {2|X ∩ Y|} {|X|+|Y|}</script><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DiceLoss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, weight=<span class="literal">None</span>, ignore_index=<span class="number">255</span>, smooth=<span class="number">1.0</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :param weight: The weight for each class</span></span><br><span class="line"><span class="string">        :param ignore_index: pecifies a target value that is ignored and does not contribute to the input gradient</span></span><br><span class="line"><span class="string">        :param smooth: Laplace smoothing to smooth dice loss and accelerate convergence</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(DiceLoss, self).__init__()</span><br><span class="line">        self.weight = weight</span><br><span class="line">        self.ignore_index = ignore_index</span><br><span class="line">        self.smooth = smooth</span><br><span class="line">        self.EPS = <span class="number">1e-8</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, logits, labels</span>):</span><br><span class="line">        num_classes = logits.shape[<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">if</span> self.weight <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            self.weight = torch.tensor(self.weight, dtype=torch.float32, device=logits.device)</span><br><span class="line">            <span class="keyword">if</span> num_classes != <span class="built_in">len</span>(self.weight):</span><br><span class="line">                <span class="keyword">raise</span> ValueError(<span class="string">&quot;The length of weight = &#123;&#125; should be same as the length of num_classes = &#123;&#125;&quot;</span>.<span class="built_in">format</span>(</span><br><span class="line">                    <span class="built_in">len</span>(self.weight), num_classes</span><br><span class="line">                ))</span><br><span class="line">        mask = labels != self.ignore_index</span><br><span class="line">        mask = mask.to(dtype=torch.long)</span><br><span class="line"></span><br><span class="line">        labels[labels == self.ignore_index] = <span class="number">0</span></span><br><span class="line">        labels_one_hot = F.one_hot(labels, num_classes)</span><br><span class="line">        labels_one_hot = torch.permute(labels_one_hot, dims=(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line">        logits = F.softmax(logits, dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        dice_loss = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_classes):</span><br><span class="line">            dice_loss_i = dice_loss_helper(logits[:, i], labels_one_hot[:, i], mask, self.smooth, self.EPS)</span><br><span class="line">            <span class="keyword">if</span> self.weight <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                dice_loss_i *= self.weight[i]</span><br><span class="line">            dice_loss += dice_loss_i</span><br><span class="line">        dice_loss /= num_classes</span><br><span class="line">        <span class="keyword">return</span> dice_loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dice_loss_helper</span>(<span class="params">logit, label, mask, smooth, eps</span>):</span><br><span class="line">    <span class="keyword">assert</span> logit.shape == label.shape, <span class="string">&quot;The shape of logit and label should be the same&quot;</span></span><br><span class="line">    num = logit.shape[<span class="number">0</span>]</span><br><span class="line">    logit = torch.reshape(logit, shape=(num, -<span class="number">1</span>))</span><br><span class="line">    label = torch.reshape(label, shape=(num, -<span class="number">1</span>))</span><br><span class="line">    mask = torch.reshape(mask, shape=(num, -<span class="number">1</span>))</span><br><span class="line">    logit *= mask</span><br><span class="line">    label *= mask</span><br><span class="line">    intersection = torch.<span class="built_in">sum</span>(logit * label, dim=<span class="number">1</span>)</span><br><span class="line">    union = torch.<span class="built_in">sum</span>(logit + label, dim=<span class="number">1</span>)</span><br><span class="line">    dice_loss = <span class="number">1</span> - (<span class="number">2</span> * intersection + smooth) / (union + smooth + eps)</span><br><span class="line">    dice_loss = dice_loss.mean()</span><br><span class="line">    <span class="keyword">return</span> dice_loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    inp = torch.randn(<span class="number">4</span>, <span class="number">20</span>, <span class="number">448</span>, <span class="number">448</span>)</span><br><span class="line">    tgt = torch.randint(low=<span class="number">0</span>, high=<span class="number">19</span>, size=(<span class="number">4</span>, <span class="number">448</span>, <span class="number">448</span>))</span><br><span class="line">    loss = DiceLoss()</span><br><span class="line">    <span class="built_in">print</span>(loss(inp, tgt))</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>图像分割</category>
      </categories>
      <tags>
        <tag>图像分割</tag>
        <tag>损失函数</tag>
      </tags>
  </entry>
  <entry>
    <title>向量距离与相似度</title>
    <url>/2022/08/30/%E5%90%91%E9%87%8F%E8%B7%9D%E7%A6%BB%E4%B8%8E%E7%9B%B8%E4%BC%BC%E5%BA%A6/</url>
    <content><![CDATA[<h1 id="向量距离与相似度"><a href="#向量距离与相似度" class="headerlink" title="向量距离与相似度"></a>向量距离与相似度</h1><p>假设当前有两个$n$维向量$x$和$y$ (除非特别说明，本文默认依此写法表示向量)，可以通过两个向量之间的距离或者相似度来判定这两个向量的相近程度，显然两个向量之间距离越小，相似度越高；两个向量之间距离越大，相似度越低。</p>
<span id="more"></span>
<h2 id="1-常见的距离计算方式"><a href="#1-常见的距离计算方式" class="headerlink" title="1. 常见的距离计算方式"></a>1. 常见的距离计算方式</h2><h3 id="1-1-闵可夫斯基距离（Minkowski-Distance）"><a href="#1-1-闵可夫斯基距离（Minkowski-Distance）" class="headerlink" title="1.1 闵可夫斯基距离（Minkowski Distance）"></a>1.1 闵可夫斯基距离（Minkowski Distance）</h3><script type="math/tex; mode=display">
Minkowski \; Distance = (\sum_{i=1}^n {|x_i - y_i|}^{p})^{\frac{1}{p}}</script><p>Minkowski Distane 是对多个距离度量公式概括性的表述，当$p=1$时，Minkowski Distane 便是曼哈顿距离；当$p=2$时，Minkowski Distane 便是欧式距离；Minkowski Distane 取极限的形式便是切比雪夫距离。</p>
<h3 id="1-2-曼哈顿距离（Manhattan-Distance）"><a href="#1-2-曼哈顿距离（Manhattan-Distance）" class="headerlink" title="1.2 曼哈顿距离（Manhattan Distance）"></a>1.2 曼哈顿距离（Manhattan Distance）</h3><script type="math/tex; mode=display">
Manhattan \; Distance = (\sum_{i=1}^n |x_i - y_i|)</script><h3 id="1-3-欧式距离-欧几里得距离（Euclidean-distance）"><a href="#1-3-欧式距离-欧几里得距离（Euclidean-distance）" class="headerlink" title="1.3 欧式距离/欧几里得距离（Euclidean distance）"></a>1.3 欧式距离/欧几里得距离（Euclidean distance）</h3><script type="math/tex; mode=display">
Euclidean \; Distance = \sqrt{\sum_{i=1}^n (x_i - y_i)^2}</script><h3 id="1-4-切比雪夫距离（Chebyshev-Distance）"><a href="#1-4-切比雪夫距离（Chebyshev-Distance）" class="headerlink" title="1.4 切比雪夫距离（Chebyshev Distance）"></a>1.4 切比雪夫距离（Chebyshev Distance）</h3><script type="math/tex; mode=display">
\underset{p \rightarrow \infty}{\text{lim}} (\sum_{i=1}^n {|x_i - y_i|}^{p})^{\frac{1}{p}} = \text{max} \; (|x_i-y_i|)</script><h3 id="1-5-海明距离（Hamming-Distance）"><a href="#1-5-海明距离（Hamming-Distance）" class="headerlink" title="1.5 海明距离（Hamming Distance）"></a>1.5 海明距离（Hamming Distance）</h3><p> 在信息论中，两个等长字符串之间的海明距离是两个字符串对应位置的不同字符的个数。假设有两个字符串分别是：$x=[x_1,x_2,…,x_n]$和$y=[y_1,y_2,…,y_n]$，则两者的距离为：</p>
<script type="math/tex; mode=display">
Hamming \; Distance  = \sum_{i=1}^{n} {\text{II}}(x_i=y_i)</script><p>其中$\text{II}$表示指示函数，两者相同为1，否则为0。</p>
<h3 id="1-6-KL散度"><a href="#1-6-KL散度" class="headerlink" title="1.6 KL散度"></a>1.6 KL散度</h3><p>在信息论中，随机变量$X$的熵表示如下：</p>
<script type="math/tex; mode=display">H=-\sum_{i=1}^Np(x_i)\cdot logp(x_i)</script><p>给定随机变量$X$和两个概率分布$P$和$Q$，KL散度可以用来衡量两个分布之间的差异性，又叫相对熵。其公式如下：</p>
<script type="math/tex; mode=display">
KL(P||Q)= \sum_{x \in X} p(x)log\,\frac{P(x)}{Q(x)}</script><h2 id="2-常见的相似度函数"><a href="#2-常见的相似度函数" class="headerlink" title="2. 常见的相似度函数"></a>2. 常见的相似度函数</h2><h3 id="2-1-余弦相似度（Cosine-Similarity）"><a href="#2-1-余弦相似度（Cosine-Similarity）" class="headerlink" title="2.1 余弦相似度（Cosine Similarity）"></a>2.1 余弦相似度（Cosine Similarity）</h3><script type="math/tex; mode=display">
\begin{align}
Cosine \; Similarity = \frac{x \cdot y}{|x|\cdot |y|} = \frac{\sum_{i=1}^n x_iy_i}{\sqrt{\sum_{i=1}^n x_i^2}\sqrt{\sum_{i=1}^n y_i^2}}
\end{align}</script><h3 id="2-2-皮尔逊相关系数-（Pearson-Correlation-Coefficient）"><a href="#2-2-皮尔逊相关系数-（Pearson-Correlation-Coefficient）" class="headerlink" title="2.2 皮尔逊相关系数 （Pearson Correlation Coefficient）"></a>2.2 皮尔逊相关系数 （Pearson Correlation Coefficient）</h3><p>给定两个随机变量$X$和$Y$，皮尔逊相关系数可以用来衡量两者的相关程度，公式如下:</p>
<script type="math/tex; mode=display">
\begin{align}
\rho_{x,y} &= \frac{cov(X,Y)}{\sigma_X \sigma_Y} = \frac{E[(X-\mu_X)(Y-\mu_Y)]}{\sigma_X \sigma_Y} \\
& = \frac{\sum_{i=1}^n (X_i - \bar{X})(Y_i-\bar{Y})}{\sqrt{\sum_{i=1}^n(X_i-\bar{X})^2}\sqrt{\sum_{i=1}^n(Y_i-\bar{Y})^2}}
\end{align}</script><p>其中$\mu_X$和$\mu_Y$分别表示向量$X$和$Y$的均值，$\sigma_X$和$\sigma_Y$分别表示向量$X$和$Y$的标准差。</p>
<h3 id="2-3-Jaccard-相似系数（Jaccard-Coefficient）"><a href="#2-3-Jaccard-相似系数（Jaccard-Coefficient）" class="headerlink" title="2.3 Jaccard 相似系数（Jaccard Coefficient）"></a>2.3 Jaccard 相似系数（Jaccard Coefficient）</h3><p>假设有两个集合$X$和$Y$(注意这里的两者不是向量)，则其计算公式为：</p>
<script type="math/tex; mode=display">
Jaccard(X,Y)=\frac{X\cap Y}{X\cup Y}</script>]]></content>
      <categories>
        <category>深度学习基础</category>
      </categories>
      <tags>
        <tag>向量</tag>
        <tag>相似度</tag>
      </tags>
  </entry>
  <entry>
    <title>评估指标</title>
    <url>/2022/08/30/%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87/</url>
    <content><![CDATA[<h1 id="评估指标"><a href="#评估指标" class="headerlink" title="评估指标"></a>评估指标</h1><p>常见评价指标有精度、精确率、召回率、P-R曲线、F1 值、TPR、FPR、ROC、AUC等指标，还有在生物领域常用的敏感性、特异性等指标。</p>
<span id="more"></span>
<h2 id="1-图像分类评估指标"><a href="#1-图像分类评估指标" class="headerlink" title="1. 图像分类评估指标"></a>1. 图像分类评估指标</h2><p>在分类任务中，各指标的计算基础都来自于对正负样本的分类结果，用混淆矩阵表示，如 <strong>图1</strong> 所示：</p>
<center><img src="https://raw.githubusercontent.com/w5688414/paddleImage/main/metrics_img/confusion_metric.png" width="500" hegiht="" ></center>
<center><br>图1 混淆矩阵 </br></center>

<h3 id="1-1-精度"><a href="#1-1-精度" class="headerlink" title="1.1 精度"></a>1.1 精度</h3><script type="math/tex; mode=display">Accuracy=\frac{TP+TN}{TP+FN+FP+TN}</script><p>即所有分类正确的样本占全部样本的比例。</p>
<h3 id="1-2-精确率"><a href="#1-2-精确率" class="headerlink" title="1.2 精确率"></a>1.2 精确率</h3><p>精准率又叫做：Precision、查准率</p>
<script type="math/tex; mode=display">Precision=\frac{TP}{TP+FP}</script><p>即预测是正例的结果中，确实是正例的比例。</p>
<h3 id="1-3-召回率"><a href="#1-3-召回率" class="headerlink" title="1.3 召回率"></a>1.3 召回率</h3><p>召回率又叫：Recall、查全率</p>
<script type="math/tex; mode=display">Recall=\frac{TP}{TP+FN}</script><p>即所有正例的样本中，被找出的比例</p>
<h3 id="1-4-P-R曲线"><a href="#1-4-P-R曲线" class="headerlink" title="1.4 P-R曲线"></a>1.4 P-R曲线</h3><p>P-R曲线又叫做：PRC</p>
<center><img src="https://raw.githubusercontent.com/w5688414/paddleImage/main/metrics_img/PRC.png" width="500" hegiht="" ></center>
<center><br>图2 PRC曲线图</br></center>

<p>根据预测结果将预测样本排序，最有可能为正样本的在前，最不可能的在后，依次将样本预测为正样本，分别计算当前的精确率和召回率，绘制P-R曲线。</p>
<h3 id="1-5-F1-值"><a href="#1-5-F1-值" class="headerlink" title="1.5 F1 值"></a>1.5 F1 值</h3><script type="math/tex; mode=display">F1=\frac{2 * P * R}{P + R}</script><h3 id="1-6-TPR"><a href="#1-6-TPR" class="headerlink" title="1.6 TPR"></a>1.6 TPR</h3><p>真正例率，与召回率相同</p>
<script type="math/tex; mode=display">TPR=\frac{TP}{TP+FN}</script><h3 id="1-7-FPR"><a href="#1-7-FPR" class="headerlink" title="1.7 FPR"></a>1.7 FPR</h3><p>假正例率</p>
<script type="math/tex; mode=display">FPR=\frac{FP}{TN+FP}</script><h3 id="1-8-ROC"><a href="#1-8-ROC" class="headerlink" title="1.8 ROC"></a>1.8 ROC</h3><p>根据预测结果将预测样本排序，最有可能为正样本的在前，最不可能的在后，依次将样本预测为正样本，分别计算当前的TPR和FPR，绘制ROC曲线。</p>
<h3 id="1-9-AUC"><a href="#1-9-AUC" class="headerlink" title="1.9 AUC"></a>1.9 AUC</h3><p>Area Under ROC Curve，ROC曲线下的面积：</p>
<center><img src="https://raw.githubusercontent.com/w5688414/paddleImage/main/metrics_img/AUC.png" width="500" hegiht="" ></center>
<center><br>图3 ROC曲线图</br></center>

<h3 id="1-10-敏感性"><a href="#1-10-敏感性" class="headerlink" title="1.10 敏感性"></a>1.10 敏感性</h3><p>敏感性或者灵敏度（Sensitivity，也称为真阳性率）是指实际为阳性的样本中，判断为阳性的比例（例如真正有生病的人中，被医院判断为有生病者的比例），计算方式是真阳性除以真阳性+假阴性（实际为阳性，但判断为阴性）的比值（能将实际患病的病例正确地判断为患病的能力，即患者被判为阳性的概率）。公式如下：</p>
<script type="math/tex; mode=display">sensitivity =\frac{TP}{TP + FN}</script><p>即有病（阳性）人群中，检测出阳性的几率。（检测出确实有病的能力）</p>
<h3 id="1-11-特异性"><a href="#1-11-特异性" class="headerlink" title="1.11 特异性"></a>1.11 特异性</h3><p>特异性或特异度（Specificity，也称为真阴性率）是指实际为阴性的样本中，判断为阴性的比例（例如真正未生病的人中，被医院判断为未生病者的比例），计算方式是真阴性除以真阴性+假阳性（实际为阴性，但判断为阳性）的比值（能正确判断实际未患病的病例的能力，即试验结果为阴性的比例）。公式如下：</p>
<script type="math/tex; mode=display">specificity =\frac{TN}{TN + FP}</script><p>即无病（阴性）人群中，检测出阴性的几率。（检测出确实没病的能力）</p>
<h2 id="2-目标检测评估指标"><a href="#2-目标检测评估指标" class="headerlink" title="2. 目标检测评估指标"></a>2. 目标检测评估指标</h2><h2 id="3-图像分割评估指标"><a href="#3-图像分割评估指标" class="headerlink" title="3. 图像分割评估指标"></a>3. 图像分割评估指标</h2><h2 id="4-OCR评估指标"><a href="#4-OCR评估指标" class="headerlink" title="4. OCR评估指标"></a>4. OCR评估指标</h2><h2 id="5-GAN评估指标"><a href="#5-GAN评估指标" class="headerlink" title="5. GAN评估指标"></a>5. GAN评估指标</h2>]]></content>
      <categories>
        <category>深度学习基础</category>
      </categories>
      <tags>
        <tag>数学</tag>
        <tag>模型评估</tag>
      </tags>
  </entry>
</search>
