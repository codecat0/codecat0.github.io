<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>FCN</title>
    <url>/2021/12/30/FCN/</url>
    <content><![CDATA[<h1 id="FCN论文详解"><a href="#FCN论文详解" class="headerlink" title="FCN论文详解"></a>FCN论文详解</h1><blockquote>
<p>FCN全卷积网络是图像分割开山之作，其核心思想非常简单，用卷积层代替分类网络中的全连接层。</p>
</blockquote>
<span id="more"></span>

<h2 id="1-将全连接层替换为卷积层"><a href="#1-将全连接层替换为卷积层" class="headerlink" title="1. 将全连接层替换为卷积层"></a>1. 将全连接层替换为卷积层</h2><p>语义分割的目的是<strong>对图像中每一个像素点进行分类</strong>，与普通的分类任务只输出图像某个类别不同，<strong>语义分割任务输出的是与输入图像大小相同的图像，输出图像的每个像素对应输入图像每个像素的类别</strong>，这也就是论文中提到的<code>dense prediction</code>。</p>
<p>FCN全卷积网络是图像分割开山之作，其核心思想非常简单，<strong>用卷积层代替分类网络中的全连接层。</strong><br><img src="https://img-blog.csdnimg.cn/781c58979f904f4a8f9f2fcc1b8fd57e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5L2V5aaC5Y2D5rO3,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<p>用于分类的神经网络由卷积层、池化层和最后连接的全连接层组成，<strong>经过最后的全连接层后，二维的图像信息被映射为具体的一维类别信息进行输出，得到分类标签。</strong></p>
<p>对于语义分割问题，我们需要的不是具体的类别标签，而是一个二维的分割图，<strong>FCN方法丢弃全连接层，并将其换成卷积层，最后输出与原图相同大小的分割图</strong></p>
<p><strong>论文作者认为：全连接层让目标的位置信息消失了，只保留了语义信息，而将全连接层更换为卷积层可以同时保留位置信息和语义信息</strong><br><img src="https://img-blog.csdnimg.cn/21e775adbf0d437887fe31716099c2f4.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5L2V5aaC5Y2D5rO3,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<h2 id="2-上采样"><a href="#2-上采样" class="headerlink" title="2. 上采样"></a>2. 上采样</h2><p>由于经过<strong>多次卷积之后图像的大小会缩小</strong>，需要通过<strong>上采样</strong>对其进行尺寸大小的恢复，<strong>使最后的分割图与原图尺寸一样</strong></p>
<h3 id="2-1-反卷积"><a href="#2-1-反卷积" class="headerlink" title="2.1 反卷积"></a>2.1 反卷积</h3><p>下图为<code>stride=1、paddding=0</code>的反卷积的工作过程<br><img src="https://img-blog.csdnimg.cn/c50c7c3bebd142d48d93551748d7fcf2.gif#pic_center" alt="在这里插入图片描述"></p>
<p>下图为<code>stride=2、padding=1</code>的反卷积的工作过程<br><img src="https://img-blog.csdnimg.cn/d241df84e06e4314a0ffe52a15eb4a88.gif#pic_center" alt="在这里插入图片描述"></p>
<p>根据<strong>卷积</strong>的尺寸计算公式<br>$$o&#x3D;\frac {i-k+2 \cdot p} {s} + 1$$<br>得<strong>反卷积</strong>的尺寸就算公式为：<br>$$i &#x3D; (o-1) \cdot s + k - 2 \cdot p$$</p>
<p><strong>Pytorch实现</strong>：<a href="https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html?highlight=nn%20convtranspose2d#torch.nn.ConvTranspose2d">nn.ConvTranspose2d</a></p>
<h3 id="2-2-插值"><a href="#2-2-插值" class="headerlink" title="2.2 插值"></a>2.2 <a href="https://blog.csdn.net/qq_42735631/article/details/117751529">插值</a></h3><h4 id="2-2-1-最近邻插值"><a href="#2-2-1-最近邻插值" class="headerlink" title="2.2.1 最近邻插值"></a>2.2.1 最近邻插值</h4><p><img src="https://img-blog.csdnimg.cn/c3b2878c047a49d599dc626a8b30ae6d.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5L2V5aaC5Y2D5rO3,size_12,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<p>计算<strong>P</strong>与<strong>Q11、Q12、Q22、Q21</strong>的<strong>距离</strong>，<strong>可知P与Q11最近，所以P像素点的值与Q11像素点的值一样</strong></p>
<h4 id="2-2-2-双线性插值"><a href="#2-2-2-双线性插值" class="headerlink" title="2.2.2 双线性插值"></a>2.2.2 双线性插值</h4><p><img src="https://img-blog.csdnimg.cn/67e57649e93249488cb3b22d58a265d4.png#pic_center" alt="在这里插入图片描述"></p>
<p>双线性插值就是做两次线性变换，先在<strong>X</strong>轴上做一次线性变换，求出每一行的<strong>R</strong>点<br>$$R_1&#x3D;\frac {x_2-x} {x_2-x_1} Q_{11} + \frac {x-x_1} {x_2-x_1}Q_{21} \ R_2&#x3D;\frac {x_2-x} {x_2-x_1} Q_{12} + \frac {x-x_1} {x_2-x_1} Q_{22}$$<br>再在<strong>Y</strong>轴上做一次线性变换，求该区域的<strong>P</strong>点<br>$$P&#x3D;\frac {y_2-y} {y_2-y_1}R_1 + \frac {y-y_1} {y_2-y_1}R_2$$</p>
<h3 id="2-3-UpPooling"><a href="#2-3-UpPooling" class="headerlink" title="2.3 UpPooling"></a>2.3 <a href="https://pytorch.org/docs/stable/generated/torch.nn.MaxUnpool2d.html?highlight=nn%20unpool#torch.nn.MaxUnpool2d">UpPooling</a></h3><p><img src="https://img-blog.csdnimg.cn/ada957a8efea4989a4c96c3a57b5ef6f.png#pic_center" alt="在这里插入图片描述"></p>
<h3 id="2-4-Upsample"><a href="#2-4-Upsample" class="headerlink" title="2.4 Upsample"></a>2.4 <a href="https://pytorch.org/docs/stable/generated/torch.nn.Upsample.html">Upsample</a></h3><h2 id="3-跳跃结构"><a href="#3-跳跃结构" class="headerlink" title="3. 跳跃结构"></a>3. 跳跃结构</h2><p>如果<strong>直接用全卷积后的层进行上采样的话，得到的结果往往不够精细</strong>，所以本文中采取了跳级结构的方法，<strong>将更靠前的卷积层和经过上采样的层相结合</strong>，如下图所示：<br><img src="https://img-blog.csdnimg.cn/fdd748ead141469b9837c157e3d89fe3.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5L2V5aaC5Y2D5rO3,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<p>采用这种方法，能够<strong>在保留全局特征的前提下，尽可能使得图像的划分更为精细</strong></p>
]]></content>
      <categories>
        <category>图像分割</category>
      </categories>
      <tags>
        <tag>模型</tag>
        <tag>图像分割</tag>
      </tags>
  </entry>
  <entry>
    <title>DeepLab</title>
    <url>/2022/06/17/DeepLab/</url>
    <content><![CDATA[<h1 id="DeepLab系列"><a href="#DeepLab系列" class="headerlink" title="DeepLab系列"></a>DeepLab系列</h1><blockquote>
<p>本文介绍了DeepLabV1、DeepLabV2、DeepLabV3和DeepLabV3+四种模型，并使用Pytorch进行了实现。</p>
</blockquote>
<span id="more"></span>

<h2 id="1-DeepLabV1"><a href="#1-DeepLabV1" class="headerlink" title="1. DeepLabV1"></a>1. DeepLabV1</h2><h3 id="1-1-语义分割中存在的问题"><a href="#1-1-语义分割中存在的问题" class="headerlink" title="1.1 语义分割中存在的问题"></a>1.1 语义分割中存在的问题</h3><p><strong>1. 信号下采样导致分辨率降低</strong></p>
<ul>
<li>造成原因：采用<code>MaxPooling</code>造成的</li>
<li>解决办法：引入<code>atrous Conv</code>空洞卷积</li>
</ul>
<p><strong>2. CNN的空间不变性</strong></p>
<ul>
<li>造成原因：重复的池化和下采样</li>
<li>解决办法：使用<code>DenseCRF</code></li>
</ul>
<h3 id="1-2-空洞卷积"><a href="#1-2-空洞卷积" class="headerlink" title="1.2 空洞卷积"></a>1.2 空洞卷积</h3><p>空洞卷积通过引入扩张率<code>Dilation Rate</code>这一参数使得同样尺寸的卷积核获得更大的感受野</p>
<p><strong>1. 扩张率为1的3*3卷积，其与标准卷积一样</strong><br><img src="https://img-blog.csdnimg.cn/31476414ebdc41c68c896051c1c83e18.png#pic_center" alt="在这里插入图片描述"></p>
<p><strong>2. 扩张率为2的3*3卷积</strong><br><img src="https://img-blog.csdnimg.cn/fbe8fc72eca34ab6ab9a4b205c2b2d8a.png#pic_center" alt="在这里插入图片描述"></p>
<p><strong>3. 扩张率为4的3*3卷积</strong><br><img src="https://img-blog.csdnimg.cn/e03b1634326e46b39c5d68231e612ec4.png#pic_center" alt="在这里插入图片描述"></p>
<h3 id="1-3-网络结构"><a href="#1-3-网络结构" class="headerlink" title="1.3 网络结构"></a>1.3 网络结构</h3><p><strong>使用VGG16模型作为backbone</strong></p>
<ul>
<li>将VGG16中的全连接层转化为卷积层</li>
<li>将VGG16中的<code>MaxPooling</code>层由<code>kernel=2, stride=2</code>转化为<code>kernel=3, stride=2, padding=1</code>，并且最后两个<code>MaxPooling</code>层的<code>stride</code>全部设置为<code>1</code></li>
<li>将VGG16中的最后三个卷积层修改为空洞卷积，扩张率为2；并且第一个全连接层卷积化也修改为空洞卷积，在论文中<code>LargeFOV</code>中的设置为<code>12</code></li>
</ul>
<p><strong>Pytorch实现</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># !/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*-coding:utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"># File       : backbone.py</span></span><br><span class="line"><span class="string"># Author     ：CodeCat</span></span><br><span class="line"><span class="string"># version    ：python 3.7</span></span><br><span class="line"><span class="string"># Software   ：Pycharm</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">conv3x3</span>(<span class="params">in_channels, out_channels, stride=<span class="number">1</span>, dilation=<span class="number">1</span>, padding=<span class="number">1</span></span>):</span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">        nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">3</span>, stride=stride, padding=padding, dilation=dilation),</span><br><span class="line">        nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">conv1x1</span>(<span class="params">in_channels, out_channels, stride=<span class="number">1</span>, dilation=<span class="number">1</span>, padding=<span class="number">1</span></span>):</span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">        nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">1</span>, stride=stride, padding=padding, dilation=dilation),</span><br><span class="line">        nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Block</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels, num_depth=<span class="number">2</span>, padding=<span class="number">1</span>, dilation=<span class="number">1</span>, pool_stride=<span class="number">2</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Block, self).__init__()</span><br><span class="line">        self.num_depth = num_depth</span><br><span class="line">        self.conv1 = conv3x3(in_channels, out_channels, padding=padding, dilation=dilation)</span><br><span class="line">        self.conv2 = conv3x3(out_channels, out_channels, padding=padding, dilation=dilation)</span><br><span class="line">        <span class="keyword">if</span> self.num_depth == <span class="number">3</span>:</span><br><span class="line">            self.conv3 = conv3x3(out_channels, out_channels, padding=padding, dilation=dilation)</span><br><span class="line">        self.pool = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=pool_stride, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        x = self.conv2(x)</span><br><span class="line">        <span class="keyword">if</span> self.num_depth == <span class="number">3</span>:</span><br><span class="line">            x = self.conv3(x)</span><br><span class="line">        x = self.pool(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DeepLabV1</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes=<span class="number">21</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(DeepLabV1, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.block1 = Block(in_channels=<span class="number">3</span>, out_channels=<span class="number">64</span>)</span><br><span class="line">        self.block2 = Block(in_channels=<span class="number">64</span>, out_channels=<span class="number">128</span>)</span><br><span class="line">        self.block3 = Block(in_channels=<span class="number">128</span>, out_channels=<span class="number">256</span>, num_depth=<span class="number">3</span>)</span><br><span class="line">        self.block4 = Block(in_channels=<span class="number">256</span>, out_channels=<span class="number">512</span>, num_depth=<span class="number">3</span>, pool_stride=<span class="number">1</span>)</span><br><span class="line">        self.block5 = Block(in_channels=<span class="number">512</span>, out_channels=<span class="number">512</span>, num_depth=<span class="number">3</span>, pool_stride=<span class="number">1</span>, dilation=<span class="number">2</span>, padding=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        self.avg_pool = nn.AvgPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        self.conv6 = conv3x3(in_channels=<span class="number">512</span>, out_channels=<span class="number">1024</span>, padding=<span class="number">12</span>, dilation=<span class="number">12</span>)</span><br><span class="line">        self.drop6 = nn.Dropout2d(p=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">        self.conv7 = conv1x1(in_channels=<span class="number">1024</span>, out_channels=<span class="number">1024</span>, padding=<span class="number">0</span>)</span><br><span class="line">        self.drop7 = nn.Dropout2d(p=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">        self.conv8 = conv1x1(in_channels=<span class="number">1024</span>, out_channels=num_classes, padding=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        input_size = x.shape[-<span class="number">2</span>:]</span><br><span class="line">        <span class="comment"># (b, 3, 224, 224) -&gt; (b, 64, 112, 112)</span></span><br><span class="line">        x = self.block1(x)</span><br><span class="line">        <span class="comment"># (b, 64, 112, 112) -&gt; (b, 128, 56, 56)</span></span><br><span class="line">        x = self.block2(x)</span><br><span class="line">        <span class="comment"># (b, 128, 56, 56) -&gt; (b, 256, 28, 28)</span></span><br><span class="line">        x = self.block3(x)</span><br><span class="line">        <span class="comment"># (b, 256, 28, 28) -&gt; (b, 512, 28, 28)</span></span><br><span class="line">        x = self.block4(x)</span><br><span class="line">        <span class="comment"># (b, 512, 28, 28) -&gt; (b, 512, 28, 28)</span></span><br><span class="line">        x = self.block5(x)</span><br><span class="line">        <span class="comment"># (b, 512, 28, 28) -&gt; (b, 512, 28, 28)</span></span><br><span class="line">        x = self.avg_pool(x)</span><br><span class="line">        <span class="comment"># (b, 512, 28, 28) -&gt; (b, 1024, 28, 28)</span></span><br><span class="line">        x = self.conv6(x)</span><br><span class="line">        x = self.drop6(x)</span><br><span class="line">        <span class="comment"># (b, 1024, 28, 28) -&gt; (b, 1024, 28, 28)</span></span><br><span class="line">        x = self.conv7(x)</span><br><span class="line">        x = self.drop7(x)</span><br><span class="line">        <span class="comment"># (b, 1024, 28, 28) -&gt; (b, num_classes, 28, 28)</span></span><br><span class="line">        x = self.conv8(x)</span><br><span class="line">        <span class="comment"># (b, num_classes, 28, 28) -&gt; (b, num_classes, 224, 224)</span></span><br><span class="line">        x = F.interpolate(x, size=input_size, mode=<span class="string">&#x27;bilinear&#x27;</span>, align_corners=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    model = DeepLabV1()</span><br><span class="line">    inputs = torch.randn(<span class="number">2</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>)</span><br><span class="line">    outputs = model(inputs)</span><br><span class="line">    <span class="built_in">print</span>(outputs.shape)</span><br></pre></td></tr></table></figure>
<h2 id="2-DeepLabV2"><a href="#2-DeepLabV2" class="headerlink" title="2. DeepLabV2"></a>2. DeepLabV2</h2><h3 id="2-1-语义分割中存在的问题"><a href="#2-1-语义分割中存在的问题" class="headerlink" title="2.1 语义分割中存在的问题"></a>2.1 语义分割中存在的问题</h3><ol>
<li>分辨率被降低导致特征层丢失细节信息：主要由于下采样<code>stride&gt;1</code>的层造成的</li>
<li>目标的多尺度问题</li>
<li>DCNNs的不变性会降低定位精度</li>
</ol>
<h3 id="2-1-论文中的解决办法"><a href="#2-1-论文中的解决办法" class="headerlink" title="2.1 论文中的解决办法"></a>2.1 论文中的解决办法</h3><ol>
<li>针对问题1，一般是将最后几个<code>MaxPooling</code>层的<code>stride</code>设置为1（若是通过卷积进行下采样，也是将其<code>stride</code>设置为1），然后再配合空洞卷积</li>
<li>针对问题2，本文提出了<code>ASPP</code>模块</li>
<li>针对问题3，和DeepLabV1一样采用<code>DenseCRF</code></li>
</ol>
<h3 id="2-3-ASPP模块"><a href="#2-3-ASPP模块" class="headerlink" title="2.3 ASPP模块"></a>2.3 ASPP模块</h3><p><strong>并行采用多个采样率的空洞卷积提取特征，再将特征进行融合，该结构称为空洞空间金字塔池化</strong><br><img src="https://img-blog.csdnimg.cn/c381fd7f04344a5da13c03ef66598439.png#pic_center" alt="在这里插入图片描述"></p>
<h3 id="2-4-网络结构"><a href="#2-4-网络结构" class="headerlink" title="2.4 网络结构"></a>2.4 网络结构</h3><p><strong>与DeepLabV1使用VGG16作为backbone不同的是，DeepLabV2使用ResNet101作为backbone，做出的修改如下：</strong></p>
<ol>
<li>将<code>Layer3</code>中的<code>Bottleneck1</code>中原本进行下采样的<code>3x3</code>卷积层(<code>stride=2</code>)的<code>stride</code>设置为<code>1</code>，即不进行下采样，并且<code>3x3</code>卷积层全部采用扩张率为<code>2</code>的空洞卷积</li>
<li>将<code>Layer4</code>中的<code>Bottleneck1</code>中原本进行下采样的<code>3x3</code>卷积层(<code>stride=2</code>)的<code>stride</code>设置为<code>1</code>，即不进行下采样，并且<code>3x3</code>卷积层全部采用扩张率为<code>4</code>的空洞卷积</li>
<li><code>ASPP</code>模块中的每一个分支只有一个<code>3x3</code>的空洞卷积层，并且卷积核的个数等于<code>num_classes</code></li>
</ol>
<p><strong>Pytorch实现</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># !/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*-coding:utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"># File       : backbone.py</span></span><br><span class="line"><span class="string"># Author     ：CodeCat</span></span><br><span class="line"><span class="string"># version    ：python 3.7</span></span><br><span class="line"><span class="string"># Software   ：Pycharm</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Bottleneck</span>(nn.Module):</span><br><span class="line">    expansion = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels, stride=<span class="number">1</span>, dilation=<span class="number">1</span>, downsample=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Bottleneck, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">1</span>, stride=stride, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(out_channels)</span><br><span class="line"></span><br><span class="line">        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=dilation, dilation=dilation, bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(out_channels)</span><br><span class="line"></span><br><span class="line">        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)</span><br><span class="line"></span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.downsample = downsample</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        identity = x</span><br><span class="line">        <span class="keyword">if</span> self.downsample <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            identity = self.downsample(x)</span><br><span class="line"></span><br><span class="line">        out = self.relu(self.bn1(self.conv1(x)))</span><br><span class="line"></span><br><span class="line">        out = self.relu(self.bn2(self.conv2(out)))</span><br><span class="line"></span><br><span class="line">        out = self.conv3(out)</span><br><span class="line">        out = self.bn3(out)</span><br><span class="line"></span><br><span class="line">        out += identity</span><br><span class="line">        out = self.relu(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ASPP</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels, atrous_rates</span>):</span><br><span class="line">        <span class="built_in">super</span>(ASPP, self).__init__()</span><br><span class="line">        <span class="keyword">for</span> i, rate <span class="keyword">in</span> <span class="built_in">enumerate</span>(atrous_rates):</span><br><span class="line">            self.add_module(<span class="string">&#x27;c%d&#x27;</span>%i, nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=rate, dilation=rate, bias=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">sum</span>([stage(x) <span class="keyword">for</span> stage <span class="keyword">in</span> self.children()])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DeepLabV2</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes, block_nums, atrous_rates</span>):</span><br><span class="line">        <span class="built_in">super</span>(DeepLabV2, self).__init__()</span><br><span class="line">        self.in_channels = <span class="number">64</span></span><br><span class="line"></span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, self.in_channels, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(self.in_channels)</span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.maxpool = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        self.layer1 = self._make_layer(<span class="number">64</span>, block_nums[<span class="number">0</span>])</span><br><span class="line">        self.layer2 = self._make_layer(<span class="number">128</span>, block_nums[<span class="number">1</span>], stride=<span class="number">2</span>)</span><br><span class="line">        self.layer3 = self._make_layer(<span class="number">256</span>, block_nums[<span class="number">2</span>], dilation=<span class="number">2</span>)</span><br><span class="line">        self.layer4 = self._make_layer(<span class="number">512</span>, block_nums[<span class="number">3</span>], dilation=<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">        self.aspp = ASPP(in_channels=<span class="number">512</span> * Bottleneck.expansion, out_channels=num_classes, atrous_rates=atrous_rates)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        input_size = x.shape[-<span class="number">2</span>:]</span><br><span class="line">        <span class="comment"># (b, 3, 224, 224) -&gt; (b, 64, 112, 112)</span></span><br><span class="line">        x = self.relu(self.bn1(self.conv1(x)))</span><br><span class="line">        <span class="comment"># (b, 64, 112, 112) -&gt; (b, 64, 56, 56)</span></span><br><span class="line">        x = self.maxpool(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># (b, 64, 56, 56) -&gt; (b, 256, 56, 56)</span></span><br><span class="line">        x = self.layer1(x)</span><br><span class="line">        <span class="comment"># (b, 256, 56, 56) -&gt; (b, 512, 28, 28)</span></span><br><span class="line">        x = self.layer2(x)</span><br><span class="line">        <span class="comment"># (b, 512, 28, 28) -&gt; (b, 1024, 28, 28)</span></span><br><span class="line">        x = self.layer3(x)</span><br><span class="line">        <span class="comment"># (b, 1024, 28, 28) -&gt; (b, 2048, 28, 28)</span></span><br><span class="line">        x = self.layer4(x)</span><br><span class="line">        <span class="comment"># (b, 2048, 28, 28) -&gt; (b, num_classes, 28, 28)</span></span><br><span class="line">        x = self.aspp(x)</span><br><span class="line">        <span class="comment"># (b, num_classes, 28, 28) -&gt; (b, num_classes, 224, 224)</span></span><br><span class="line">        x = F.interpolate(x, size=input_size, mode=<span class="string">&#x27;bilinear&#x27;</span>, align_corners=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_make_layer</span>(<span class="params">self, channels, block_num, stride=<span class="number">1</span>, dilation=<span class="number">1</span></span>):</span><br><span class="line">        downsample = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> stride != <span class="number">1</span> <span class="keyword">or</span> self.in_channels != channels * Bottleneck.expansion:</span><br><span class="line">            downsample = nn.Sequential(</span><br><span class="line">                nn.Conv2d(self.in_channels, channels * Bottleneck.expansion, kernel_size=<span class="number">1</span>, stride=stride, bias=<span class="literal">False</span>),</span><br><span class="line">                nn.BatchNorm2d(channels * Bottleneck.expansion)</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        layers = <span class="built_in">list</span>()</span><br><span class="line"></span><br><span class="line">        layers.append(Bottleneck(self.in_channels, channels, downsample=downsample, stride=stride, dilation=dilation))</span><br><span class="line">        self.in_channels = channels * Bottleneck.expansion</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, block_num):</span><br><span class="line">            layers.append(Bottleneck(self.in_channels, channels, dilation=dilation))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    model = DeepLabV2(</span><br><span class="line">        num_classes=<span class="number">21</span>,</span><br><span class="line">        block_nums=[<span class="number">3</span>, <span class="number">4</span>, <span class="number">23</span>, <span class="number">3</span>],</span><br><span class="line">        atrous_rates=[<span class="number">6</span>, <span class="number">12</span>, <span class="number">18</span>, <span class="number">24</span>]</span><br><span class="line">    )</span><br><span class="line">    inputs = torch.randn(<span class="number">2</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>)</span><br><span class="line">    outputs = model(inputs)</span><br><span class="line">    <span class="built_in">print</span>(outputs.shape)</span><br></pre></td></tr></table></figure>


<h2 id="3-DeepLabV3"><a href="#3-DeepLabV3" class="headerlink" title="3. DeepLabV3"></a>3. DeepLabV3</h2><p><strong>改进了ASPP模块</strong></p>
<h3 id="3-1-ASPP模块"><a href="#3-1-ASPP模块" class="headerlink" title="3.1 ASPP模块"></a>3.1 ASPP模块</h3><p><img src="https://img-blog.csdnimg.cn/img_convert/3adb3fe220965bd35443645f8d50fafb.png"></p>
<p><strong>ASPP模块</strong></p>
<ul>
<li>一个<code>1x1</code>卷积</li>
<li>三个<code>3x3</code>空洞卷积，当<code>output_stride=16</code>时，<code>rates=(6, 12, 18)</code>；当<code>output_stride=8</code>时，扩张率翻倍，即<code>rates=(12, 24, 36)</code></li>
<li>图像级特征：将特征做全局平均池化，后<code>1x1</code>卷积，再上采样</li>
<li>每个卷积层后面会加入<code>BN</code>层</li>
</ul>
<p><strong><code>output_stride</code>说明</strong></p>
<ul>
<li>表示输入图像大小与输出特征图大小的比值</li>
<li>在图像分类任务中，最终的输出特征图比输入图像大小小32倍，即<code>output_stride=32</code></li>
<li>在语义分割任务中，<code>output_stride</code>一般为<code>8</code>或<code>16</code>，通常通过改变最后1个或2个block，使其不再缩小特征图的大小，并应用空洞卷积来密集提取特征<br><strong>Pytorch实现</strong><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ASPP</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels, rate=<span class="number">1</span>, bn_momentum=<span class="number">0.1</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(ASPP, self).__init__()</span><br><span class="line">        self.branch1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, out_channels, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), stride=<span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channels, momentum=bn_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">        self.branch2 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, out_channels, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=<span class="number">1</span>, padding=<span class="number">6</span>*rate, dilation=<span class="number">6</span>*rate),</span><br><span class="line">            nn.BatchNorm2d(out_channels, momentum=bn_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">        self.branch3 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, out_channels, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=<span class="number">1</span>, padding=<span class="number">12</span>*rate, dilation=<span class="number">12</span>*rate),</span><br><span class="line">            nn.BatchNorm2d(out_channels, momentum=bn_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">        self.branch4 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, out_channels, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=<span class="number">1</span>, padding=<span class="number">18</span>*rate, dilation=<span class="number">18</span>*rate),</span><br><span class="line">            nn.BatchNorm2d(out_channels, momentum=bn_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">        self.branch5 = nn.Sequential(</span><br><span class="line">            nn.AdaptiveAvgPool2d(output_size=(<span class="number">1</span>, <span class="number">1</span>)),</span><br><span class="line">            nn.Conv2d(in_channels, out_channels, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), stride=<span class="number">1</span>, padding=<span class="number">0</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channels, momentum=bn_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.conv_cat = nn.Sequential(</span><br><span class="line">            nn.Conv2d(out_channels*<span class="number">5</span>, out_channels, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), stride=<span class="number">1</span>, padding=<span class="number">0</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channels, momentum=bn_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        b, c, h, w = x.size()</span><br><span class="line"></span><br><span class="line">        conv1x1 = self.branch1(x)</span><br><span class="line">        conv3x3_1 = self.branch2(x)</span><br><span class="line">        conv3x3_2 = self.branch3(x)</span><br><span class="line">        conv3x3_3 = self.branch4(x)</span><br><span class="line"></span><br><span class="line">        global_feature = self.branch5(x)</span><br><span class="line">        global_feature = F.interpolate(global_feature, size=(h, w), mode=<span class="string">&#x27;bilinear&#x27;</span>, align_corners=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        feature_cat = torch.cat([conv1x1, conv3x3_1, conv3x3_2, conv3x3_3, global_feature], dim=<span class="number">1</span>)</span><br><span class="line">        result = self.conv_cat(feature_cat)</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    model = ASPP(in_channels=<span class="number">2048</span>, out_channels=<span class="number">2048</span>)</span><br><span class="line">    inputs = torch.randn(<span class="number">2</span>, <span class="number">2048</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">    outputs = model(inputs)</span><br><span class="line">    <span class="built_in">print</span>(outputs.shape)</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="4-DeepLabV3"><a href="#4-DeepLabV3" class="headerlink" title="4. DeepLabV3+"></a>4. DeepLabV3+</h2><h3 id="4-1-简介"><a href="#4-1-简介" class="headerlink" title="4.1 简介"></a>4.1 简介</h3><p><strong>DeepLabV3+不仅采用了ASPP结构，而且还采用了编码器-解码器结构</strong></p>
<h3 id="4-2-网络结构"><a href="#4-2-网络结构" class="headerlink" title="4.2 网络结构"></a>4.2 网络结构</h3><p><img src="https://img-blog.csdnimg.cn/img_convert/68e93e65300bce0b7042a77ddcb20e90.png"><br>网络的<strong>编码器</strong>结构与<code>DeepLabV3</code>一样。<br><strong>解码器</strong>与<code>DeepLabV3</code>不一样，<code>DeepLabV3</code>以<code>factor=16</code>直接进行上采样，而<code>DeepLabV3+</code>采用层级解码器，不是一步到位的，而是通过如下步骤：</p>
<ul>
<li>首先将编码器提取的特征图进行<code>factor=4</code>的上采样，然后和尺寸相同的<code>low-level</code>特征进行<code>concat</code>拼接</li>
<li><code>low-level</code>特征首先采用<code>1x1</code>卷积进行降维，这样能够使得编码器提取的特征有一个偏重</li>
<li>最后再采用<code>3x3</code>卷积进一步提取特征，再以<code>factor=4</code>进行上采样</li>
</ul>
<hr>
<p><strong>完整代码：</strong> <a href="https://github.com/codecat0/CV/tree/main/Semantic_Segmentation/DeepLabV3%2B">https://github.com/codecat0/CV/tree/main/Semantic_Segmentation&#x2F;DeepLabV3+</a></p>
]]></content>
      <categories>
        <category>图像分割</category>
      </categories>
      <tags>
        <tag>模型</tag>
        <tag>图像分割</tag>
      </tags>
  </entry>
  <entry>
    <title>U-Net</title>
    <url>/2021/12/27/U-Net/</url>
    <content><![CDATA[<h1 id="U-Net论文详解"><a href="#U-Net论文详解" class="headerlink" title="U-Net论文详解"></a>U-Net论文详解</h1><blockquote>
<p>U-Net结构由一个用于捕获上下文信息的压缩路径和一个支持精确定位的对称扩展路径构成。实验结果表明可以从很少的图像进行端到端的训练，并在ISBI挑战上优于先前最优的方法(滑动窗口卷积网络)，并获得了冠军</p>
</blockquote>
<span id="more"></span>

<h2 id="1-背景介绍"><a href="#1-背景介绍" class="headerlink" title="1. 背景介绍"></a>1. 背景介绍</h2><p>卷积网络的典型应用是分类任务，其中图像的输出是一个单一的类标签。然而在许多视觉任务中，特别是生物医学图像处理中，期望的输出应该包含定位，即给每一个像素点分配一个类标签。</p>
<p>于是滑动窗口卷积网络通过提供像素点周围的局部区域来预测每个像素的类别标签。但是这样的方法存在两个缺点：</p>
<ol>
<li>速度特别慢，网络必须为每一个窗口单元单独运行，并且窗口单元重合而导致大量冗余</li>
<li>在定位精度和上下文信息之间的权衡。大的窗口单元需要更多的max pooling层，这会降低精度；而小的窗口单元捕获的上下文信息较少。</li>
</ol>
<p>于是本文提出了U-Net网络</p>
<h2 id="2-U-Net网络架构"><a href="#2-U-Net网络架构" class="headerlink" title="2. U-Net网络架构"></a>2. U-Net网络架构</h2><p><img src="https://img-blog.csdnimg.cn/ee65efa0cb8e4ceabf581b6ab7a9281e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5L2V5aaC5Y2D5rO3,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<p><strong>网络是一个经典的全卷积网络。网络的输入是一张572x572经过镜像操作的图像。为了使得每次下采样后特征图的尺寸为偶数。</strong><br><img src="https://img-blog.csdnimg.cn/ab4fe06a1a854b6ebd19b575a37c0c3e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5L2V5aaC5Y2D5rO3,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<p>网络的左侧为<strong>压缩路径</strong>，由<strong>4个block</strong>构成，<strong>每个block由2个未padding的卷积和一个最大池化构成，其中每次卷积特征图的尺寸为减小2，最大池化后会缩小一半。</strong></p>
<p><strong>现在大部分采用same padding的卷积，这样就不用对输入进行镜像操作，而且在拼接压缩路径与对应的扩展路径也不用进行裁剪，而且裁剪会使得特征图不对称</strong></p>
<p>网络的右侧为<strong>扩展路径</strong>，同样由<strong>4个bloc</strong>k构成，每个block开始之前通过<strong>反卷积将特征图的尺寸扩大一倍</strong>，然后与压缩路径对应的特征图拼接，<strong>由于采用未padding的卷积，左侧压缩路径的特征图的尺寸比右侧扩展路径的特征图的大，所以需要先进行裁剪，使其大小相同，然后拼接</strong>，然后<strong>经过两次未padding的卷积</strong>进一步提取特征</p>
<p>最后根据自己的任务，输出对应大小的预测特征图</p>
<p>现在大部分采用<strong>双线性插值代替反卷积</strong>，而且效果会更好</p>
<h2 id="3-数据增强"><a href="#3-数据增强" class="headerlink" title="3. 数据增强"></a>3. 数据增强</h2><p>我们主要通过平移和旋转不变性以及灰度值的变化来增强模型的鲁棒性，特别地，<strong>任意的弹性形变对训练非常有帮助</strong>。</p>
<h2 id="4-Pytorch实现"><a href="#4-Pytorch实现" class="headerlink" title="4. Pytorch实现"></a>4. Pytorch实现</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Encoder</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels</span>):</span><br><span class="line">        <span class="built_in">super</span>(Encoder, self).__init__()</span><br><span class="line">        self.block1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">        self.block2 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(out_channels, out_channels, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">        self.pool = nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.block1(x)</span><br><span class="line">        x = self.block2(x)</span><br><span class="line">        x_pooled = self.pool(x)</span><br><span class="line">        <span class="keyword">return</span> x, x_pooled</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Decoder</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels</span>):</span><br><span class="line">        <span class="built_in">super</span>(Decoder, self).__init__()</span><br><span class="line">        self.up_sample = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line">        self.block1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">        self.block2 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(out_channels, out_channels, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x_prev, x</span>):</span><br><span class="line">        x = self.up_sample(x)</span><br><span class="line">        x_shape = x.shape[<span class="number">2</span>:]</span><br><span class="line">        x_prev_shape = x.shape[<span class="number">2</span>:]</span><br><span class="line">        h_diff = x_prev_shape[<span class="number">0</span>] - x_shape[<span class="number">0</span>]</span><br><span class="line">        w_diff = x_prev_shape[<span class="number">1</span>] - x_shape[<span class="number">1</span>]</span><br><span class="line">        <span class="comment"># padding</span></span><br><span class="line">        x_tmp = torch.zeros(x_prev.shape).to(x.device)</span><br><span class="line">        x_tmp[:, :, h_diff//<span class="number">2</span>: h_diff+x_shape[<span class="number">0</span>], w_diff//<span class="number">2</span>: x_shape[<span class="number">1</span>]] = x</span><br><span class="line">        x = torch.cat([x_prev, x_tmp], dim=<span class="number">1</span>)</span><br><span class="line">        x = self.block1(x)</span><br><span class="line">        x = self.block2(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">UNet</span>(nn.Module):</span><br><span class="line">    <span class="comment"># https://arxiv.org/abs/1505.04597</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes=<span class="number">2</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(UNet, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.down_sample1 = Encoder(in_channels=<span class="number">3</span>, out_channels=<span class="number">64</span>)</span><br><span class="line">        self.down_sample2 = Encoder(in_channels=<span class="number">64</span>, out_channels=<span class="number">128</span>)</span><br><span class="line">        self.down_sample3 = Encoder(in_channels=<span class="number">128</span>, out_channels=<span class="number">256</span>)</span><br><span class="line">        self.down_sample4 = Encoder(in_channels=<span class="number">256</span>, out_channels=<span class="number">512</span>)</span><br><span class="line"></span><br><span class="line">        self.mid1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">512</span>, <span class="number">1024</span>, <span class="number">3</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">        self.mid2 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">1024</span>, <span class="number">1024</span>, <span class="number">3</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.up_sample1 = Decoder(in_channels=<span class="number">1024</span>, out_channels=<span class="number">512</span>)</span><br><span class="line">        self.up_sample2 = Decoder(in_channels=<span class="number">512</span>, out_channels=<span class="number">256</span>)</span><br><span class="line">        self.up_sample3 = Decoder(in_channels=<span class="number">256</span>, out_channels=<span class="number">128</span>)</span><br><span class="line">        self.up_sample4 = Decoder(in_channels=<span class="number">128</span>, out_channels=<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line">        self.classifier = nn.Conv2d(<span class="number">64</span>, num_classes, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x1, x = self.down_sample1(x)</span><br><span class="line">        x2, x = self.down_sample2(x)</span><br><span class="line">        x3, x = self.down_sample3(x)</span><br><span class="line">        x4, x = self.down_sample4(x)</span><br><span class="line"></span><br><span class="line">        x = self.mid1(x)</span><br><span class="line">        x = self.mid2(x)</span><br><span class="line"></span><br><span class="line">        x = self.up_sample1(x4, x)</span><br><span class="line">        x = self.up_sample2(x3, x)</span><br><span class="line">        x = self.up_sample3(x2, x)</span><br><span class="line">        x = self.up_sample4(x1, x)</span><br><span class="line"></span><br><span class="line">        x = self.classifier(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="built_in">input</span> = torch.rand(<span class="number">1</span>, <span class="number">3</span>, <span class="number">384</span>, <span class="number">384</span>)</span><br><span class="line">    model = UNet(<span class="number">2</span>)</span><br><span class="line">    out = model(<span class="built_in">input</span>)</span><br><span class="line">    <span class="built_in">print</span>(out.shape)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>图像分割</category>
      </categories>
      <tags>
        <tag>模型</tag>
        <tag>图像分割</tag>
      </tags>
  </entry>
  <entry>
    <title>图像分割损失函数汇总</title>
    <url>/2022/08/29/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E6%B1%87%E6%80%BB/</url>
    <content><![CDATA[<h1 id="图像分割损失函数汇总"><a href="#图像分割损失函数汇总" class="headerlink" title="图像分割损失函数汇总"></a>图像分割损失函数汇总</h1><p>在本文中，总结了大多数广泛应用于图像分割的损失函数，并通过<code>Pytorch</code>框架进行了实现。</p>
<span id="more"></span>

<h2 id="1-BCELoss："><a href="#1-BCELoss：" class="headerlink" title="1. BCELoss："></a>1. BCELoss：</h2><p>$$l(x,y)&#x3D;L&#x3D;{l_1,…,l_N}^T$$<br>$$l_n&#x3D;-w_n[y_n \cdot logx_n + (1-y_n) \cdot log(1-x_n)]$$</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BCELoss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 weight=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 pos_weight=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 ignore_index=<span class="number">255</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :param weight: A manual rescaling weight given to the loss of each batch element</span></span><br><span class="line"><span class="string">        :param pos_weight: A weight of positive examples</span></span><br><span class="line"><span class="string">        :param ignore_index: Specifies a target value that is ignored and does not contribute to the input gradient</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(BCELoss, self).__init__()</span><br><span class="line">        self.weight = weight</span><br><span class="line">        self.pos_weight = pos_weight</span><br><span class="line">        self.ignore_index = ignore_index</span><br><span class="line">        self.EPS = <span class="number">1e-10</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, logit, label</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :param logit: Logit tensor, the data type is float32, float64. Shape is</span></span><br><span class="line"><span class="string">                (N, C), where C is number of classes, and if shape is more than 2D, this</span></span><br><span class="line"><span class="string">                is (N, C, D1, D2,..., Dk), k &gt;= 1.</span></span><br><span class="line"><span class="string">        :param label: Label tensor, the data type is int64. Shape is (N, C), where each</span></span><br><span class="line"><span class="string">                value is 0 or 1, and if shape is more than 2D, this is</span></span><br><span class="line"><span class="string">                (N, C, D1, D2,..., Dk), k &gt;= 1.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(label.shape) != <span class="built_in">len</span>(logit.shape):</span><br><span class="line">            label = torch.unsqueeze(label, dim=<span class="number">1</span>)</span><br><span class="line">        mask = (label != self.ignore_index)</span><br><span class="line">        mask = mask.to(dtype=torch.float32)</span><br><span class="line">        <span class="keyword">if</span> label.shape[<span class="number">1</span>] != logit.shape[<span class="number">1</span>]:</span><br><span class="line">            label = label.squeeze(<span class="number">1</span>)</span><br><span class="line">            label = F.one_hot(label, logit.shape[<span class="number">1</span>])</span><br><span class="line">            label = torch.permute(label, dims=(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line">        label = label.to(dtype=torch.float32)</span><br><span class="line">        loss = F.binary_cross_entropy_with_logits(</span><br><span class="line">            <span class="built_in">input</span>=logit,</span><br><span class="line">            target=label,</span><br><span class="line">            weight=self.weight,</span><br><span class="line">            pos_weight=self.pos_weight,</span><br><span class="line">            reduction=<span class="string">&#x27;none&#x27;</span></span><br><span class="line">        )</span><br><span class="line">        loss = loss * mask</span><br><span class="line">        loss = torch.mean(loss) / (torch.mean(mask) + self.EPS)</span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    inp = torch.randn(<span class="number">4</span>, <span class="number">21</span>, <span class="number">448</span>, <span class="number">448</span>)</span><br><span class="line">    tgt = torch.randint(low=<span class="number">0</span>, high=<span class="number">20</span>, size=(<span class="number">4</span>, <span class="number">448</span>, <span class="number">448</span>))</span><br><span class="line">    loss = BCELoss()</span><br><span class="line">    <span class="built_in">print</span>(loss(inp, tgt))</span><br></pre></td></tr></table></figure>

<h2 id="2-CrossEntropyLoss"><a href="#2-CrossEntropyLoss" class="headerlink" title="2.CrossEntropyLoss:"></a>2.CrossEntropyLoss:</h2><p>$$l(x, y)&#x3D; L &#x3D; {l_1, …, l_N}^T$$<br>$$l_n&#x3D;-w_{y_n}log \frac {exp(x_{n, y_n})} {\sum_{c&#x3D;1}^C exp(x_{n,c})} \cdot 1{y_n \not &#x3D; ignore_index}$$</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CELoss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 weight=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 ignore_index=<span class="number">255</span>,</span></span><br><span class="line"><span class="params">                 top_k_percent_pixels=<span class="number">1.0</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :param weight: (tuple|list|ndarray|Tensor, optional): A manual rescaling weight</span></span><br><span class="line"><span class="string">            given to each class. Its length must be equal to the number of classes.</span></span><br><span class="line"><span class="string">        :param ignore_index: (int64, optional): Specifies a target value that is ignored</span></span><br><span class="line"><span class="string">            and does not contribute to the input gradient. Default ``255``.</span></span><br><span class="line"><span class="string">        :param top_k_percent_pixels: (float, optional): the value lies in [0.0, 1.0].</span></span><br><span class="line"><span class="string">            When its value &lt; 1.0, only compute the loss for the top k percent pixels</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(CELoss, self).__init__()</span><br><span class="line">        self.weight = weight</span><br><span class="line">        self.ignore_index = ignore_index</span><br><span class="line">        self.top_k_percent_pixels = top_k_percent_pixels</span><br><span class="line">        self.EPS = <span class="number">1e-8</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, logit, label, semantic_weights=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :param logit: Logit tensor, the data type is float32, float64. Shape is</span></span><br><span class="line"><span class="string">                (N, C), where C is number of classes, and if shape is more than 2D, this</span></span><br><span class="line"><span class="string">                is (N, C, D1, D2,..., Dk), k &gt;= 1.</span></span><br><span class="line"><span class="string">        :param label: Label tensor, the data type is int64. Shape is (N), where each</span></span><br><span class="line"><span class="string">                value is 0 &lt;= label[i] &lt;= C-1, and if shape is more than 2D, this is</span></span><br><span class="line"><span class="string">                (N, D1, D2,..., Dk), k &gt;= 1.</span></span><br><span class="line"><span class="string">        :param semantic_weights: Weights about loss for each pixels,</span></span><br><span class="line"><span class="string">                shape is the same as label. Default: None.</span></span><br><span class="line"><span class="string">        :return: (Tensor): The average loss.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> self.weight <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            self.weight = torch.tensor(self.weight, dtype=torch.float32, device=logit.device)</span><br><span class="line">            <span class="keyword">if</span> logit.shape[<span class="number">1</span>] != <span class="built_in">len</span>(self.weight):</span><br><span class="line">                <span class="keyword">raise</span> ValueError(<span class="string">&quot;The number of weights = &#123;&#125; must be the same as the number of classes = &#123;&#125;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(self.weight), logit.shape[<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line">        label = label.to(dtype=torch.int64)</span><br><span class="line">        loss = F.cross_entropy(</span><br><span class="line">            <span class="built_in">input</span>=logit,</span><br><span class="line">            target=label,</span><br><span class="line">            ignore_index=self.ignore_index,</span><br><span class="line">            reduction=<span class="string">&#x27;none&#x27;</span>,</span><br><span class="line">            weight=self.weight</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">return</span> self._post_process_loss(logit, label, semantic_weights, loss)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_post_process_loss</span>(<span class="params">self, logit, label, semantic_weights, loss</span>):</span><br><span class="line">        mask = label != self.ignore_index</span><br><span class="line">        mask = mask.to(dtype=torch.float32)</span><br><span class="line">        <span class="keyword">if</span> loss.ndim &gt; mask.ndim:</span><br><span class="line">            loss = torch.squeeze(loss, dim=-<span class="number">1</span>)</span><br><span class="line">        loss = loss * mask</span><br><span class="line">        <span class="keyword">if</span> semantic_weights <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            loss = loss * semantic_weights</span><br><span class="line">        <span class="keyword">if</span> self.weight <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            _one_hot = F.one_hot(label * mask, logit.shape[<span class="number">1</span>])</span><br><span class="line">            coef = torch.<span class="built_in">sum</span>(_one_hot * self.weight, dim=-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            coef = torch.ones_like(label)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.top_k_percent_pixels == <span class="number">1.0</span>:</span><br><span class="line">            avg_loss = torch.mean(loss) / (torch.mean(mask * coef) + self.EPS)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            loss = loss.reshape((-<span class="number">1</span>, ))</span><br><span class="line">            top_k_pixels = <span class="built_in">int</span>(self.top_k_percent_pixels * loss.numel())</span><br><span class="line">            loss, indices = torch.topk(loss, top_k_pixels)</span><br><span class="line">            coef = coef.reshape((-<span class="number">1</span>, ))</span><br><span class="line">            coef = torch.gather(coef, dim=<span class="number">0</span>, index=indices)</span><br><span class="line">            coef = coef.to(dtype=torch.float32)</span><br><span class="line">            coef.requires_grad = <span class="literal">True</span></span><br><span class="line">            avg_loss = loss.mean() / (torch.mean(coef) + self.EPS)</span><br><span class="line">        <span class="keyword">return</span> avg_loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    inp = torch.randn(<span class="number">4</span>, <span class="number">21</span>, <span class="number">448</span>, <span class="number">448</span>)</span><br><span class="line">    tgt = torch.randint(low=<span class="number">0</span>, high=<span class="number">20</span>, size=(<span class="number">4</span>, <span class="number">448</span>, <span class="number">448</span>))</span><br><span class="line">    loss = CELoss(top_k_percent_pixels=<span class="number">0.8</span>)</span><br><span class="line">    <span class="built_in">print</span>(loss(inp, tgt))</span><br></pre></td></tr></table></figure>

<h2 id="3-Focal-Loss"><a href="#3-Focal-Loss" class="headerlink" title="3. Focal Loss:"></a>3. Focal Loss:</h2><p><img src="https://production-media.paperswithcode.com/methods/Screen_Shot_2020-06-07_at_4.45.06_PM_leJm2yh.png"></p>
<p>$$ CE(p_t) &#x3D; -log(p_t)$$<br>$$FL(p_t)&#x3D;-\alpha(1-p_t)^\gamma log(p_t)$$</p>
<p>其中：$p_t&#x3D;\frac {exp(x_{n, t})} {\sum_{c&#x3D;1}^C exp(x_{n,c})}$表示样本属于<code>true class</code>的概率，$\alpha , \gamma$是超参数。</p>
<p>通过添加$(1-p_t)^\gamma$的目的是：<strong>减少易分类样本的权重，从而使得模型在训练时更专注于难分类的样本。</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FocalLoss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, alpha=<span class="number">1.0</span>, gamma=<span class="number">2.0</span>, ignore_index=<span class="number">255</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :param alpha: The alpha of Focal Loss</span></span><br><span class="line"><span class="string">        :param gamma: The gamma of Focal Loss</span></span><br><span class="line"><span class="string">        :param ignore_index: Specifies a target value that is ignored and does not contribute to the input gradient</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(FocalLoss, self).__init__()</span><br><span class="line">        self.alpha = alpha</span><br><span class="line">        self.gamma = gamma</span><br><span class="line">        self.ignore_index = ignore_index</span><br><span class="line">        self.EPS = <span class="number">1e-10</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, logit, label</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :param logit: Logit tensor, the data type is float32, float64. Shape is</span></span><br><span class="line"><span class="string">                (N, C, H, W), where C is number of classes.</span></span><br><span class="line"><span class="string">        :param label: Label tensor, the data type is int64. Shape is (N, H, W),</span></span><br><span class="line"><span class="string">                where each value is 0 &lt;= label[i] &lt;= C-1.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">assert</span> logit.ndim == <span class="number">4</span>, <span class="string">&quot;The ndim of logit should be 4&quot;</span></span><br><span class="line">        <span class="keyword">assert</span> label.ndim == <span class="number">3</span>, <span class="string">&quot;The ndim of label should be 3&quot;</span></span><br><span class="line">        label = label.to(dtype=torch.int64)</span><br><span class="line">        ce_loss = F.cross_entropy(</span><br><span class="line">            <span class="built_in">input</span>=logit,</span><br><span class="line">            target=label,</span><br><span class="line">            ignore_index=self.ignore_index,</span><br><span class="line">            reduction=<span class="string">&#x27;none&#x27;</span></span><br><span class="line">        )</span><br><span class="line">        pt = torch.exp(-ce_loss)</span><br><span class="line">        focal_loss = self.alpha * ((<span class="number">1</span> - pt) ** self.gamma) * ce_loss</span><br><span class="line">        mask = label != self.ignore_index</span><br><span class="line">        mask = mask.to(dtype=torch.float32)</span><br><span class="line">        focal_loss *= mask</span><br><span class="line">        avg_loss = torch.mean(focal_loss) / (torch.mean(mask) + self.EPS)</span><br><span class="line">        <span class="keyword">return</span> avg_loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    inp = torch.randn(<span class="number">4</span>, <span class="number">21</span>, <span class="number">448</span>, <span class="number">448</span>)</span><br><span class="line">    tgt = torch.randint(low=<span class="number">0</span>, high=<span class="number">20</span>, size=(<span class="number">4</span>, <span class="number">448</span>, <span class="number">448</span>))</span><br><span class="line">    loss = FocalLoss()</span><br><span class="line">    <span class="built_in">print</span>(loss(inp, tgt))</span><br></pre></td></tr></table></figure>

<h2 id="4-Dice-Loss"><a href="#4-Dice-Loss" class="headerlink" title="4. Dice Loss"></a>4. Dice Loss</h2><p>$$L_{dice}&#x3D;1-\frac {2|X ∩ Y|} {|X|+|Y|}$$</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DiceLoss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, weight=<span class="literal">None</span>, ignore_index=<span class="number">255</span>, smooth=<span class="number">1.0</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :param weight: The weight for each class</span></span><br><span class="line"><span class="string">        :param ignore_index: pecifies a target value that is ignored and does not contribute to the input gradient</span></span><br><span class="line"><span class="string">        :param smooth: Laplace smoothing to smooth dice loss and accelerate convergence</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(DiceLoss, self).__init__()</span><br><span class="line">        self.weight = weight</span><br><span class="line">        self.ignore_index = ignore_index</span><br><span class="line">        self.smooth = smooth</span><br><span class="line">        self.EPS = <span class="number">1e-8</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, logits, labels</span>):</span><br><span class="line">        num_classes = logits.shape[<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">if</span> self.weight <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            self.weight = torch.tensor(self.weight, dtype=torch.float32, device=logits.device)</span><br><span class="line">            <span class="keyword">if</span> num_classes != <span class="built_in">len</span>(self.weight):</span><br><span class="line">                <span class="keyword">raise</span> ValueError(<span class="string">&quot;The length of weight = &#123;&#125; should be same as the length of num_classes = &#123;&#125;&quot;</span>.<span class="built_in">format</span>(</span><br><span class="line">                    <span class="built_in">len</span>(self.weight), num_classes</span><br><span class="line">                ))</span><br><span class="line">        mask = labels != self.ignore_index</span><br><span class="line">        mask = mask.to(dtype=torch.long)</span><br><span class="line"></span><br><span class="line">        labels[labels == self.ignore_index] = <span class="number">0</span></span><br><span class="line">        labels_one_hot = F.one_hot(labels, num_classes)</span><br><span class="line">        labels_one_hot = torch.permute(labels_one_hot, dims=(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line">        logits = F.softmax(logits, dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        dice_loss = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_classes):</span><br><span class="line">            dice_loss_i = dice_loss_helper(logits[:, i], labels_one_hot[:, i], mask, self.smooth, self.EPS)</span><br><span class="line">            <span class="keyword">if</span> self.weight <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                dice_loss_i *= self.weight[i]</span><br><span class="line">            dice_loss += dice_loss_i</span><br><span class="line">        dice_loss /= num_classes</span><br><span class="line">        <span class="keyword">return</span> dice_loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dice_loss_helper</span>(<span class="params">logit, label, mask, smooth, eps</span>):</span><br><span class="line">    <span class="keyword">assert</span> logit.shape == label.shape, <span class="string">&quot;The shape of logit and label should be the same&quot;</span></span><br><span class="line">    num = logit.shape[<span class="number">0</span>]</span><br><span class="line">    logit = torch.reshape(logit, shape=(num, -<span class="number">1</span>))</span><br><span class="line">    label = torch.reshape(label, shape=(num, -<span class="number">1</span>))</span><br><span class="line">    mask = torch.reshape(mask, shape=(num, -<span class="number">1</span>))</span><br><span class="line">    logit *= mask</span><br><span class="line">    label *= mask</span><br><span class="line">    intersection = torch.<span class="built_in">sum</span>(logit * label, dim=<span class="number">1</span>)</span><br><span class="line">    union = torch.<span class="built_in">sum</span>(logit + label, dim=<span class="number">1</span>)</span><br><span class="line">    dice_loss = <span class="number">1</span> - (<span class="number">2</span> * intersection + smooth) / (union + smooth + eps)</span><br><span class="line">    dice_loss = dice_loss.mean()</span><br><span class="line">    <span class="keyword">return</span> dice_loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    inp = torch.randn(<span class="number">4</span>, <span class="number">20</span>, <span class="number">448</span>, <span class="number">448</span>)</span><br><span class="line">    tgt = torch.randint(low=<span class="number">0</span>, high=<span class="number">19</span>, size=(<span class="number">4</span>, <span class="number">448</span>, <span class="number">448</span>))</span><br><span class="line">    loss = DiceLoss()</span><br><span class="line">    <span class="built_in">print</span>(loss(inp, tgt))</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>图像分割</category>
      </categories>
      <tags>
        <tag>图像分割</tag>
        <tag>损失函数</tag>
      </tags>
  </entry>
  <entry>
    <title>SegNet</title>
    <url>/2021/12/31/SegNet/</url>
    <content><![CDATA[<h1 id="SegNet论文详解"><a href="#SegNet论文详解" class="headerlink" title="SegNet论文详解"></a>SegNet论文详解</h1><p>本文提出了一种用于语义分割的深度全卷积神经网络结构SegNet，其核心<strong>由一个编码器网络和一个对应的解码器网络以及一个像素级分类层组成</strong>。</p>
<span id="more"></span>

<p>本文的创新在于：<br>解码器使用在对应编码器的最大池化步骤中计算的<strong>池化索引</strong>来执行非线性上采样，这与反卷积相比，减少了参数量和运算量，而且消除了学习上采样的需要。<br><img src="https://img-blog.csdnimg.cn/0ed48fd837404b7da916fc0ed8d4cbf8.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5L2V5aaC5Y2D5rO3,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<h2 id="1-网络结构"><a href="#1-网络结构" class="headerlink" title="1. 网络结构"></a>1. 网络结构</h2><p><img src="https://img-blog.csdnimg.cn/28ab3c4e856447e4b981ecfdcad3055c.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5L2V5aaC5Y2D5rO3,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<h3 id="1-1-编码器"><a href="#1-1-编码器" class="headerlink" title="1.1 编码器"></a>1.1 编码器</h3><ol>
<li>Conv层<ul>
<li>通过卷积提取特征，其中使用的是<code>same padding</code>的卷积，不会改变特征图的尺寸</li>
</ul>
</li>
<li>BN层<ul>
<li>起到归一化的作用</li>
</ul>
</li>
<li>ReLU层<ul>
<li>起到激活函数的作用</li>
</ul>
</li>
<li>Pooling层<ul>
<li><code>max pooling</code>层，同时会<strong>记录最大值的索引位置</strong></li>
</ul>
</li>
</ol>
<h3 id="1-2-解码器"><a href="#1-2-解码器" class="headerlink" title="1.2 解码器"></a>1.2 解码器</h3><ol>
<li><p>Upsampling层<br><img src="https://img-blog.csdnimg.cn/0afcb64febd349909cc66e0ca58966fc.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5L2V5aaC5Y2D5rO3,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<ul>
<li>对输入的特征图放大两倍，然后把输入特征图的数据根据编码器<code>pooling</code>层的<strong>索引位置</strong>放入，<strong>其他位置为0</strong></li>
</ul>
</li>
<li><p>Conv层</p>
<ul>
<li>通过卷积提取特征，其中使用的是<code>same padding</code>的卷积，不会改变特征图的尺寸</li>
</ul>
</li>
<li><p>BN层</p>
<ul>
<li>起到归一化的作用</li>
</ul>
</li>
<li><p>ReLU层</p>
<ul>
<li>起到激活函数的作用</li>
</ul>
</li>
</ol>
<h3 id="1-3-像素级分类层"><a href="#1-3-像素级分类层" class="headerlink" title="1.3 像素级分类层"></a>1.3 像素级分类层</h3><p>输出每一个像素点在所有类别概率，其中<strong>最大的概率类别为该像素的预测值</strong></p>
<h2 id="2-Pytorch实现"><a href="#2-Pytorch实现" class="headerlink" title="2. Pytorch实现"></a>2. Pytorch实现</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Encoder</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels</span>):</span><br><span class="line">        <span class="built_in">super</span>(Encoder, self).__init__()</span><br><span class="line"></span><br><span class="line">        batchNorm_momentum = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line">        self.encode1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, <span class="number">64</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">64</span>, momentum=batchNorm_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">64</span>, momentum=batchNorm_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.encode2 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">64</span>, <span class="number">128</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">128</span>, momentum=batchNorm_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">128</span>, <span class="number">128</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">128</span>, momentum=batchNorm_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.encode3 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">128</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">256</span>, momentum=batchNorm_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">256</span>, momentum=batchNorm_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.encode4 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">256</span>, <span class="number">512</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">512</span>, momentum=batchNorm_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">512</span>, momentum=batchNorm_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.encode5 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">512</span>, momentum=batchNorm_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">512</span>, momentum=batchNorm_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        idx = []</span><br><span class="line"></span><br><span class="line">        x = self.encode1(x)</span><br><span class="line">        x, id1 = F.max_pool2d_with_indices(x, kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, return_indices=<span class="literal">True</span>)</span><br><span class="line">        idx.append(id1)</span><br><span class="line"></span><br><span class="line">        x = self.encode2(x)</span><br><span class="line">        x, id2 = F.max_pool2d_with_indices(x, kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, return_indices=<span class="literal">True</span>)</span><br><span class="line">        idx.append(id2)</span><br><span class="line"></span><br><span class="line">        x = self.encode3(x)</span><br><span class="line">        x, id3 = F.max_pool2d_with_indices(x, kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, return_indices=<span class="literal">True</span>)</span><br><span class="line">        idx.append(id3)</span><br><span class="line"></span><br><span class="line">        x = self.encode4(x)</span><br><span class="line">        x, id4 = F.max_pool2d_with_indices(x, kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, return_indices=<span class="literal">True</span>)</span><br><span class="line">        idx.append(id4)</span><br><span class="line"></span><br><span class="line">        x = self.encode5(x)</span><br><span class="line">        x, id5 = F.max_pool2d_with_indices(x, kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, return_indices=<span class="literal">True</span>)</span><br><span class="line">        idx.append(id5)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x, idx</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Decoder</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, out_channels</span>):</span><br><span class="line">        <span class="built_in">super</span>(Decoder, self).__init__()</span><br><span class="line"></span><br><span class="line">        batchNorm_momentum = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line">        self.decode1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">512</span>, momentum=batchNorm_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">512</span>, momentum=batchNorm_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.decode2 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">512</span>, momentum=batchNorm_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">512</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">256</span>, momentum=batchNorm_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.decode3 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">256</span>, momentum=batchNorm_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">256</span>, <span class="number">128</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">128</span>, momentum=batchNorm_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.decode4 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">128</span>, <span class="number">128</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">128</span>, momentum=batchNorm_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">128</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">64</span>, momentum=batchNorm_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.decode5 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">64</span>, momentum=batchNorm_momentum),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">64</span>, out_channels, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, idx</span>):</span><br><span class="line">        x = F.max_unpool2d(x, idx[<span class="number">4</span>], kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        x = self.decode1(x)</span><br><span class="line">        x = F.max_unpool2d(x, idx[<span class="number">3</span>], kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        x = self.decode2(x)</span><br><span class="line">        x = F.max_unpool2d(x, idx[<span class="number">2</span>], kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        x = self.decode3(x)</span><br><span class="line">        x = F.max_unpool2d(x, idx[<span class="number">1</span>], kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        x = self.decode4(x)</span><br><span class="line">        x = F.max_unpool2d(x, idx[<span class="number">0</span>], kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        x = self.decode5(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SegNet</span>(nn.Module):</span><br><span class="line">    <span class="comment"># https://arxiv.org/abs/1511.00561</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(SegNet, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.encode = Encoder(in_channels=<span class="number">3</span>)</span><br><span class="line">        self.decode = Decoder(out_channels=num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x, idx = self.encode(x)</span><br><span class="line">        x = self.decode(x, idx)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="built_in">input</span> = torch.randn(<span class="number">1</span>, <span class="number">3</span>, <span class="number">384</span>, <span class="number">544</span>)</span><br><span class="line">    model = SegNet(num_classes=<span class="number">2</span>)</span><br><span class="line">    output = model(<span class="built_in">input</span>)</span><br><span class="line">    <span class="built_in">print</span>(output.shape)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>图像分割</category>
      </categories>
      <tags>
        <tag>模型</tag>
        <tag>图像分割</tag>
      </tags>
  </entry>
</search>
